{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import json\n",
    "import re \n",
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(open(\"Oppositional_thinking_analysis_dataset.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_instances = random.sample(data, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text:str, lem_tag: bool) -> int:\n",
    "\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text) # remove decimals  \n",
    "    text = re.sub(r'[\\:\\-\\']', '', text)  # Remove specific punctuation\n",
    "    text = re.sub(r'http\\S+', '', text) # Remove URLs\n",
    "    text = re.sub(r'\\s+', ' ', text) # Remove extra whitespace\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Remove special characters\n",
    "    text = re.sub(r'\\d+\\.\\d+', '', text)  # Matches one or more digits followed by a dot and one or more digits\n",
    "    text = re.sub(r'\\bcom\\b', '', text, flags=re.IGNORECASE)  # Matches \"com\" at word boundaries (whole word)\n",
    "\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Removing stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    if bool:\n",
    "    # Lemmatization\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_texts = [preprocessing(instance['text']) for instance in selected_instances]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Use Glove vecors \n",
    "\n",
    "# Load GloVe vectors (adjust the path to where your GloVe file is located)\n",
    "def load_glove_vectors(glove_file):\n",
    "    embeddings_index = {}\n",
    "    with open(glove_file, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_vectors(tokens, embeddings_index):\n",
    "    valid_vectors = [embeddings_index[word] for word in tokens if word in embeddings_index]\n",
    "    if valid_vectors:\n",
    "        return np.mean(valid_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(100)  # Assuming GloVe 100d vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Report:\n",
      "    sentence1_id sentence2_id  cosine_similarity\n",
      "0          14037         1434           0.806338\n",
      "1          14037         4431           0.886852\n",
      "2          14037         6701           0.718611\n",
      "3          14037        11120           0.842180\n",
      "4          14037         4917           0.904956\n",
      "..           ...          ...                ...\n",
      "100        13169        10957           0.568681\n",
      "101        13169        10311           0.530114\n",
      "102         1072        10957           0.880561\n",
      "103         1072        10311           0.845229\n",
      "104        10957        10311           0.931125\n",
      "\n",
      "[105 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "glove_file = '/Users/erikrubinov/Desktop/SM24/NLP/glove.6B/glove.6B.100d.txt'  # Path to GloVe file\n",
    "embeddings_index = load_glove_vectors(glove_file)\n",
    "sentence_vectors = [average_word_vectors(tokens, embeddings_index) for tokens in preprocessed_texts]\n",
    "cosine_similarities = cosine_similarity(sentence_vectors)\n",
    "\n",
    "\n",
    "report = []\n",
    "for i in range(len(selected_instances)):\n",
    "    for j in range(i + 1, len(selected_instances)):\n",
    "        report.append({\n",
    "            'sentence1_id': selected_instances[i]['id'],\n",
    "            'sentence2_id': selected_instances[j]['id'],\n",
    "            'cosine_similarity': cosine_similarities[i, j]\n",
    "        })\n",
    "\n",
    "df_report = pd.DataFrame(report)\n",
    "print(\"Cosine Similarity Report:\")\n",
    "print(df_report)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sentence1_id sentence2_id  cosine_similarity\n",
      "0          14037         1434           0.806338\n",
      "1          14037         4431           0.886852\n",
      "2          14037         6701           0.718610\n",
      "3          14037        11120           0.842180\n",
      "4          14037         4917           0.904957\n",
      "..           ...          ...                ...\n",
      "100        13169        10957           0.568681\n",
      "101        13169        10311           0.530114\n",
      "102         1072        10957           0.880561\n",
      "103         1072        10311           0.845229\n",
      "104        10957        10311           0.931125\n",
      "\n",
      "[105 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarities_man(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "\n",
    "\n",
    "report = []\n",
    "for i in range(len(selected_instances)):\n",
    "    for j in range(i + 1, len(selected_instances)):\n",
    "        cosine_sim = cosine_similarities_man(sentence_vectors[i], sentence_vectors[j])\n",
    "        report.append({\n",
    "            'sentence1_id': selected_instances[i]['id'],\n",
    "            'sentence2_id': selected_instances[j]['id'],\n",
    "            'cosine_similarity': cosine_sim\n",
    "        })\n",
    "\n",
    "\n",
    "# Display the report\n",
    "import pandas as pd\n",
    "df_report = pd.DataFrame(report)\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec:\n",
    "# https://drive.usercontent.google.com/download?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download&authuser=0\n",
    "\n",
    "#Glove:\n",
    "#https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "import gensim.downloader as api\n",
    "word2vec_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file = open('word2vec-model.pkl', 'wb')\n",
    "pickle.dump(word2vec_model, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/Users/erikrubinov/Desktop/SM24/NLP/word2vec-model.pkl'\n",
    "\n",
    "# Load the model\n",
    "with open(model_path, 'rb') as f:\n",
    "    word2vec_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sentence1_id sentence2_id  cosine_similarity\n",
      "0          14037         1434           0.594796\n",
      "1          14037         4431           0.668467\n",
      "2          14037         6701           0.515029\n",
      "3          14037        11120           0.628776\n",
      "4          14037         4917           0.694175\n",
      "..           ...          ...                ...\n",
      "100        13169        10957           0.406916\n",
      "101        13169        10311           0.335479\n",
      "102         1072        10957           0.737388\n",
      "103         1072        10311           0.729938\n",
      "104        10957        10311           0.820351\n",
      "\n",
      "[105 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "sentence_vectors = [average_word_vectors(tokens, word2vec_model) for tokens in preprocessed_texts]\n",
    "cosine_similarities = cosine_similarity(sentence_vectors)\n",
    "\n",
    "\n",
    "\n",
    "report = []\n",
    "for i in range(len(selected_instances)):\n",
    "    for j in range(i + 1, len(selected_instances)):\n",
    "        cosine_sim = cosine_similarities_man(sentence_vectors[i], sentence_vectors[j])\n",
    "        report.append({\n",
    "            'sentence1_id': selected_instances[i]['id'],\n",
    "            'sentence2_id': selected_instances[j]['id'],\n",
    "            'cosine_similarity': cosine_sim\n",
    "        })\n",
    "\n",
    "\n",
    "# Display the report\n",
    "import pandas as pd\n",
    "df_report = pd.DataFrame(report)\n",
    "print(df_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
