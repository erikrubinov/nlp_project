{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/erikrubinov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/erikrubinov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(open(\"Oppositional_thinking_analysis_dataset.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create Dataset\n",
    "\"\"\"\n",
    "\n",
    "def balance_data(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.pop('id')\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['category'], random_state=42)\n",
    "\n",
    "    # Handle class imbalance in the training set\n",
    "    train_df_majority = train_df[train_df.category == 'CRITICAL']\n",
    "    train_df_minority = train_df[train_df.category == 'CONSPIRACY']\n",
    "\n",
    "    train_df_minority_upsampled = resample(train_df_minority, \n",
    "                                        replace=True,     \n",
    "                                        n_samples=len(train_df_majority),    \n",
    "                                        random_state=42)\n",
    "\n",
    "    train_df_balanced = pd.concat([train_df_majority, train_df_minority_upsampled])\n",
    "\n",
    "    return train_df_balanced, test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_easy(text, lem_tag = True, stem_tag = False):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "\n",
    "    if lem_tag:\n",
    "    # Lemmatization\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    if stem_tag:\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(text:str, lem_tag = True, stem_tag = False) -> int:\n",
    "\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text) # remove decimals  \n",
    "    text = re.sub(r'[\\:\\-\\']', '', text)  # Remove specific punctuation\n",
    "    text = re.sub(r'http\\S+', '', text) # Remove URLs\n",
    "    text = re.sub(r'\\s+', ' ', text) # Remove extra whitespace\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Remove special characters\n",
    "    text = re.sub(r'\\d+\\.\\d+', '', text)  # Matches one or more digits followed by a dot and one or more digits\n",
    "    text = re.sub(r'\\bcom\\b', '', text, flags=re.IGNORECASE)  # Matches \"com\" at word boundaries (whole word)\n",
    "\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Removing stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    if lem_tag:\n",
    "    # Lemmatization\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    if stem_tag:\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating CountVectorizer with preprocessing function preprocess and no Lemmatization and ngram: 1, 1...\n",
      "Results for CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  CONSPIRACY       0.78      0.77      0.78       276\n",
      "    CRITICAL       0.88      0.89      0.88       524\n",
      "\n",
      "    accuracy                           0.85       800\n",
      "   macro avg       0.83      0.83      0.83       800\n",
      "weighted avg       0.85      0.85      0.85       800\n",
      "\n",
      "Evaluating TfidfVectorizer with preprocessing function preprocess and no Lemmatization and ngram: 1, 1...\n",
      "Results for TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  CONSPIRACY       0.75      0.86      0.80       276\n",
      "    CRITICAL       0.92      0.85      0.88       524\n",
      "\n",
      "    accuracy                           0.85       800\n",
      "   macro avg       0.83      0.85      0.84       800\n",
      "weighted avg       0.86      0.85      0.85       800\n",
      "\n",
      "Evaluating CountVectorizer with preprocessing function preprocess and no Lemmatization and ngram: 1, 2...\n",
      "Results for CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  CONSPIRACY       0.76      0.80      0.78       276\n",
      "    CRITICAL       0.89      0.87      0.88       524\n",
      "\n",
      "    accuracy                           0.84       800\n",
      "   macro avg       0.83      0.83      0.83       800\n",
      "weighted avg       0.85      0.84      0.84       800\n",
      "\n",
      "Evaluating TfidfVectorizer with preprocessing function preprocess and no Lemmatization and ngram: 1, 2...\n",
      "Results for TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  CONSPIRACY       0.69      0.89      0.78       276\n",
      "    CRITICAL       0.93      0.79      0.85       524\n",
      "\n",
      "    accuracy                           0.82       800\n",
      "   macro avg       0.81      0.84      0.82       800\n",
      "weighted avg       0.85      0.82      0.83       800\n",
      "\n",
      "Evaluating CountVectorizer with preprocessing function preprocess and no Lemmatization and ngram: 2, 2...\n",
      "Results for CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  CONSPIRACY       0.76      0.70      0.73       276\n",
      "    CRITICAL       0.85      0.89      0.87       524\n",
      "\n",
      "    accuracy                           0.82       800\n",
      "   macro avg       0.80      0.79      0.80       800\n",
      "weighted avg       0.82      0.82      0.82       800\n",
      "\n",
      "Evaluating TfidfVectorizer with preprocessing function preprocess and no Lemmatization and ngram: 2, 2...\n",
      "Results for TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  CONSPIRACY       0.73      0.78      0.75       276\n",
      "    CRITICAL       0.88      0.85      0.86       524\n",
      "\n",
      "    accuracy                           0.82       800\n",
      "   macro avg       0.81      0.81      0.81       800\n",
      "weighted avg       0.83      0.82      0.83       800\n",
      "\n",
      "Evaluating CountVectorizer with preprocessing function preprocess_easy and no Lemmatization and ngram: 1, 1...\n",
      "Results for CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  CONSPIRACY       0.77      0.78      0.78       276\n",
      "    CRITICAL       0.88      0.88      0.88       524\n",
      "\n",
      "    accuracy                           0.84       800\n",
      "   macro avg       0.83      0.83      0.83       800\n",
      "weighted avg       0.85      0.84      0.85       800\n",
      "\n",
      "Evaluating TfidfVectorizer with preprocessing function preprocess_easy and no Lemmatization and ngram: 1, 1...\n",
      "Results for TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  CONSPIRACY       0.69      0.87      0.77       276\n",
      "    CRITICAL       0.92      0.79      0.85       524\n",
      "\n",
      "    accuracy                           0.82       800\n",
      "   macro avg       0.81      0.83      0.81       800\n",
      "weighted avg       0.84      0.82      0.82       800\n",
      "\n",
      "Evaluating CountVectorizer with preprocessing function preprocess_easy and no Lemmatization and ngram: 1, 2...\n",
      "Results for CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  CONSPIRACY       0.75      0.85      0.80       276\n",
      "    CRITICAL       0.92      0.85      0.88       524\n",
      "\n",
      "    accuracy                           0.85       800\n",
      "   macro avg       0.83      0.85      0.84       800\n",
      "weighted avg       0.86      0.85      0.85       800\n",
      "\n",
      "Evaluating TfidfVectorizer with preprocessing function preprocess_easy and no Lemmatization and ngram: 1, 2...\n",
      "Results for TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  CONSPIRACY       0.61      0.93      0.74       276\n",
      "    CRITICAL       0.95      0.69      0.80       524\n",
      "\n",
      "    accuracy                           0.78       800\n",
      "   macro avg       0.78      0.81      0.77       800\n",
      "weighted avg       0.84      0.78      0.78       800\n",
      "\n",
      "Evaluating CountVectorizer with preprocessing function preprocess_easy and no Lemmatization and ngram: 2, 2...\n",
      "Results for CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  CONSPIRACY       0.75      0.79      0.77       276\n",
      "    CRITICAL       0.89      0.86      0.87       524\n",
      "\n",
      "    accuracy                           0.84       800\n",
      "   macro avg       0.82      0.83      0.82       800\n",
      "weighted avg       0.84      0.84      0.84       800\n",
      "\n",
      "Evaluating TfidfVectorizer with preprocessing function preprocess_easy and no Lemmatization and ngram: 2, 2...\n",
      "Results for TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  CONSPIRACY       0.66      0.89      0.76       276\n",
      "    CRITICAL       0.93      0.76      0.83       524\n",
      "\n",
      "    accuracy                           0.80       800\n",
      "   macro avg       0.79      0.82      0.80       800\n",
      "weighted avg       0.83      0.80      0.81       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, custom_preprocess_function, use_lemmatization=True, use_stemmanization = True):\n",
    "        self.use_lemmatization = use_lemmatization\n",
    "        self.use_stemmanization = use_stemmanization\n",
    "        self.preprocess_function = custom_preprocess_function\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        res = [self.preprocess_function(text, self.use_lemmatization, self.use_stemmanization) for text in X]\n",
    "        return res\n",
    "    \n",
    "\n",
    " \n",
    "# Pre-processing pipelines\n",
    "def create_pipelines(i,j,custom_preprocess ):\n",
    "    pipelines = {\n",
    "        f'CountVectorizer with preprocessing function {custom_preprocess.__name__} and no Lemmatization and ngram: {i}, {j}': Pipeline([\n",
    "            ('preprocessor', TextPreprocessor(custom_preprocess_function=custom_preprocess, use_lemmatization=False, use_stemmanization= False)),\n",
    "            ('vectorizer', CountVectorizer(ngram_range=(i, j))),\n",
    "            ('classifier', MultinomialNB())\n",
    "        ]),\n",
    "        f'TfidfVectorizer with preprocessing function {custom_preprocess.__name__} and no Lemmatization and ngram: {i}, {j}': Pipeline([\n",
    "            ('preprocessor', TextPreprocessor(custom_preprocess_function=custom_preprocess, use_lemmatization=False, use_stemmanization= False)),\n",
    "            ('vectorizer', TfidfVectorizer(ngram_range=(i, j))),\n",
    "            ('classifier', MultinomialNB())\n",
    "        ])\n",
    "    }\n",
    "    return pipelines\n",
    "\n",
    "# Function to train and evaluate a Naïve Bayes model\n",
    "def train_and_evaluate(train_df, test_df, pipeline):\n",
    "    X_train = train_df['text']\n",
    "    #X_train = test_df[['text', 'uppercase_amount', 'comment_length']]\n",
    "\n",
    "    y_train = train_df['category']\n",
    "    X_test = test_df['text']\n",
    "    y_test = test_df['category']\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    print(f\"Results for {pipeline.named_steps['vectorizer'].__class__.__name__}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Train and evaluate models with different pipelines\n",
    "train_df_balanced = balance_data(data)[0]\n",
    "test_df = balance_data(data)[1]\n",
    "for preprocess_function in [preprocess, preprocess_easy]:\n",
    "    for i in range(1,3):\n",
    "        for j in range(1,3):\n",
    "            if i<=j:\n",
    "                pipelines = create_pipelines(i,j, preprocess_function)\n",
    "                for name, pipeline in pipelines.items():\n",
    "                    print(f\"Evaluating {name}...\")\n",
    "                    train_and_evaluate(train_df_balanced, test_df, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add feature uppercase percentage\n",
    "def calculate_uppercase_percentage(text):\n",
    "    uppercase_count = 0\n",
    "    total_letters = 0\n",
    "    \n",
    "    for char in text:\n",
    "        if char.isalpha():  # Check if the character is a letter\n",
    "            total_letters += 1\n",
    "            if char.isupper():  # Check if the letter is uppercase\n",
    "                uppercase_count += 1\n",
    "    \n",
    "    if total_letters == 0:\n",
    "        return 0\n",
    "    uppercase_percentage = (uppercase_count / total_letters) * 100\n",
    "    \n",
    "    return uppercase_percentage\n",
    "\n",
    "def classify_uppercase_percentage(percentage):\n",
    "    if percentage < 6:\n",
    "        return \"low\"\n",
    "    elif 6 <= percentage <= 12:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "# Update the data with the new key-value pair\n",
    "updated_data = []\n",
    "for comment in data:\n",
    "    uppercase_percentage = calculate_uppercase_percentage(comment[\"text\"])\n",
    "    uppercase_amount = classify_uppercase_percentage(uppercase_percentage)\n",
    "    updated_comment = comment.copy()\n",
    "    updated_comment[\"uppercase_amount\"] = uppercase_amount\n",
    "    updated_data.append(updated_comment)\n",
    "\n",
    "# Save the updated data to a new file\n",
    "with open('Oppositional_thinking_analysis_dataset.json', 'w') as f:\n",
    "    json.dump(updated_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add custom feature: comment length\n",
    "def classify_comment_lenght(length):\n",
    "    if length < 190:\n",
    "        return \"short\"\n",
    "    elif 190 <= length <= 560:\n",
    "        return \"average\"\n",
    "    else:\n",
    "        return \"long\"\n",
    "\n",
    "# Update the data with the new key-value pair\n",
    "updated_data = []\n",
    "for comment in data:\n",
    "    uppercase_amount = classify_comment_lenght(len(comment[\"text\"]))\n",
    "    updated_comment = comment.copy()\n",
    "    updated_comment[\"comment_length\"] = uppercase_amount\n",
    "    updated_data.append(updated_comment)\n",
    "\n",
    "# Save the updated data to a new file\n",
    "with open('Oppositional_thinking_analysis_dataset.json', 'w') as f:\n",
    "    json.dump(updated_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating CountVectorizer with preprocessing function preprocess_easy and no Lemmatization and ngram: 1, 1 with custom features: ['uppercase_amount', 'comment_length']...\n",
      "Results for TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  CONSPIRACY       0.77      0.82      0.79       276\n",
      "    CRITICAL       0.90      0.87      0.89       524\n",
      "\n",
      "    accuracy                           0.85       800\n",
      "   macro avg       0.83      0.84      0.84       800\n",
      "weighted avg       0.86      0.85      0.85       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, custom_preprocess_function = preprocess,  use_lemmatization=True, use_stem=False):\n",
    "        self.custom_preprocess_function = custom_preprocess\n",
    "        self.use_lemmatization = use_lemmatization\n",
    "        self.use_stem = use_stem\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_train_processed = X.copy()\n",
    "        X_train_processed['text'] = X_train_processed['text'].apply(\n",
    "            lambda x: self.custom_preprocess_function(x, lem_tag=self.use_lemmatization, stem_tag=self.use_stem))\n",
    "        return X_train_processed\n",
    "\n",
    "\n",
    "class CombinedFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, text_transformer,  additional_features = []):\n",
    "        self.text_transformer = text_transformer\n",
    "        self.additional_features = additional_features\n",
    "        self.encoder = OneHotEncoder()\n",
    "        self.vectorizer = text_transformer\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Fit the individual transformers\n",
    "        self.text_transformer.fit(X['text'])\n",
    "        if self.additional_features:\n",
    "            self.encoder.fit(X[self.additional_features]) \n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "      \n",
    "        text_features = self.text_transformer.transform(X['text'])\n",
    "     \n",
    "        if self.additional_features:\n",
    "            additional_features = self.encoder.transform(X[self.additional_features]).toarray()\n",
    "            text_features = np.hstack((text_features.toarray(), additional_features))\n",
    "       \n",
    "        return text_features\n",
    "\n",
    "# Pre-processing pipelines\n",
    "\n",
    "custom_preprocess = preprocess\n",
    "\n",
    "\n",
    "def create_pipelines(i,j,custom_preprocess, custom_feautures : list ):\n",
    "    pipelines = {\n",
    "        f'CountVectorizer with preprocessing function {custom_preprocess.__name__} and no Lemmatization and ngram: {i}, {j} with custom features: {custom_feautures}': Pipeline([\n",
    "            ('preprocessor',  TextPreprocessor(custom_preprocess_function=custom_preprocess, use_lemmatization=True, use_stem= True)),\n",
    "            ('features', CombinedFeatures(TfidfVectorizer(ngram_range=(i, j)), custom_feautures)),\n",
    "            ('classifier', MultinomialNB())\n",
    "        ]),\n",
    "\n",
    "        \n",
    "    }   \n",
    "    return pipelines\n",
    "\n",
    "\n",
    "\n",
    "# Function to train and evaluate a Naïve Bayes model\n",
    "# Function to train and evaluate a Naïve Bayes model\n",
    "def train_and_evaluate(train_df, test_df, pipeline, feature_list):\n",
    "    # Ensure both training and testing dataframes include the necessary columns\n",
    "    X_train = train_df[['text'] + feature_list]\n",
    "    y_train = train_df['category']\n",
    "    X_test = test_df[['text'] + feature_list]  # Ensure the same columns are used for X_test\n",
    "    y_test = test_df['category']\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    print(f\"Results for {pipeline.named_steps['features'].text_transformer.__class__.__name__}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Example usage of the function, assuming 'balance_data' correctly prepares the data\n",
    "for feature_list in [['uppercase_amount', 'comment_length']]:\n",
    "    for preprocess_function in [preprocess_easy]:\n",
    "        for i in range(1, 2):\n",
    "            for j in range(1, 2):\n",
    "                if i <= j:\n",
    "                    pipelines = create_pipelines(i, j, preprocess_function, feature_list)\n",
    "                    train_df_balanced, test_df = balance_data(data)  # Assume this function returns the correctly formatted data\n",
    "                    for name, pipeline in pipelines.items():\n",
    "                        print(f\"Evaluating {name}...\")\n",
    "                        train_and_evaluate(train_df_balanced, test_df, pipeline, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"CountVectorizer with preprocessing function preprocess_easy and no Lemmatization and ngram: 1, 1 with custom features: ['uppercase_amount', 'comment_length']\": Pipeline(steps=[('preprocessor',\n",
       "                  TextPreprocessor(use_lemmatization=False, use_stem=True)),\n",
       "                 ('features',\n",
       "                  CombinedFeatures(additional_features=['uppercase_amount',\n",
       "                                                        'comment_length'],\n",
       "                                   text_transformer=CountVectorizer())),\n",
       "                 ('classifier', MultinomialNB())])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip = create_pipelines(i, j, preprocess_function, feature_list)\n",
    "pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  CONSPIRACY       0.77      0.83      0.80       276\n",
      "    CRITICAL       0.91      0.87      0.89       524\n",
      "\n",
      "    accuracy                           0.85       800\n",
      "   macro avg       0.84      0.85      0.84       800\n",
      "weighted avg       0.86      0.85      0.86       800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/erikrubinov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Assuming the preprocess and preprocess2 functions are defined as before\n",
    "\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return [preprocess(text) for text in X]\n",
    "\n",
    "# Combine features using ColumnTransformer\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text_vect', TfidfVectorizer(stop_words='english'), 'text'),\n",
    "        ('uppercase_ohe', OneHotEncoder(), ['uppercase_amount'])\n",
    "    ],\n",
    "    remainder='drop'  # This drops the columns that are not specified\n",
    ")\n",
    "\n",
    "# Define the pipeline with the ColumnTransformer\n",
    "pipeline = Pipeline([\n",
    "    ('features', column_transformer),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['category'], random_state=42)\n",
    "\n",
    "# Handle class imbalance\n",
    "train_df_majority = train_df[train_df.category == 'CRITICAL']\n",
    "train_df_minority = train_df[train_df.category == 'CONSPIRACY']\n",
    "train_df_minority_upsampled = resample(train_df_minority, replace=True, n_samples=len(train_df_majority), random_state=42)\n",
    "train_df_balanced = pd.concat([train_df_majority, train_df_minority_upsampled])\n",
    "\n",
    "def train_and_evaluate(train_df, test_df, pipeline):\n",
    "    X_train = train_df[['text', 'uppercase_amount']]\n",
    "    y_train = train_df['category']\n",
    "    X_test = test_df[['text', 'uppercase_amount']]\n",
    "    y_test = test_df['category']\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    print(\"Results:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Evaluate the model\n",
    "train_and_evaluate(train_df_balanced, test_df, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
