{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5d9883f748e844",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:31:49.602734Z",
     "start_time": "2024-07-27T19:31:47.986253Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import nltk\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from preprocessing_task_2 import prepare_data\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c99c4a6b38254c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:31:59.611798Z",
     "start_time": "2024-07-27T19:31:49.603784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/erikrubinov/anaconda3/bin/python3: No module named spacy\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/erikrubinov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/erikrubinov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/erikrubinov/anaconda3/bin/python3: No module named spacy\r\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "!python3 -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "222dc7acd4ceed5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:32:08.026496Z",
     "start_time": "2024-07-27T19:31:59.613185Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fr-en/europarl-v7.fr-en.en'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m####### LOADING AND PREPROCESSING #############\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m english_data, french_data \u001b[38;5;241m=\u001b[39m prepare_data()\n",
      "File \u001b[0;32m~/Desktop/SM24/NLP/repo/nlp_project/ass2/preprocessing_task_2.py:44\u001b[0m, in \u001b[0;36mprepare_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_data\u001b[39m():\n\u001b[0;32m---> 44\u001b[0m     english_data, french_data \u001b[38;5;241m=\u001b[39m load_datasets()\n\u001b[1;32m     45\u001b[0m     preprocessed_en, preprocessed_fr \u001b[38;5;241m=\u001b[39m preprocess_data(english_data, french_data)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m preprocessed_en, preprocessed_fr\n",
      "File \u001b[0;32m~/Desktop/SM24/NLP/repo/nlp_project/ass2/helpers.py:15\u001b[0m, in \u001b[0;36mload_datasets\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m french_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfr-en/europarl-v7.fr-en.fr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m english_data \u001b[38;5;241m=\u001b[39m load_data_to_dataframe(english_file_path)\n\u001b[1;32m     16\u001b[0m french_data \u001b[38;5;241m=\u001b[39m load_data_to_dataframe(french_file_path)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m## Take 10% fraction of data randomly sampled\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/SM24/NLP/repo/nlp_project/ass2/helpers.py:8\u001b[0m, in \u001b[0;36mload_data_to_dataframe\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data_to_dataframe\u001b[39m(file_path):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Read the entire file as a single column DataFrame, ignoring any quoting\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m], encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, quoting\u001b[38;5;241m=\u001b[39mQUOTE_NONE, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/metal/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/metal/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/metal/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/envs/metal/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/metal/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fr-en/europarl-v7.fr-en.en'"
     ]
    }
   ],
   "source": [
    "####### LOADING AND PREPROCESSING #############\n",
    "english_data, french_data = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61a7669965faa00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:32:10.099989Z",
     "start_time": "2024-07-27T19:32:08.027910Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions to tokenize data and build vocab\n",
    "spacy_fr = spacy.load('fr_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize_fr(text):\n",
    "    return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "def build_vocab(sentences, vocab_size, word_tokenize):\n",
    "    all_words = [word for sentence in sentences for word in word_tokenize(sentence)]\n",
    "    word_counts = Counter(all_words)\n",
    "    vocab = [word for word, _ in word_counts.most_common(vocab_size)]\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab, start=4)}\n",
    "    word2idx['<pad>'] = 0\n",
    "    word2idx['<unk>'] = 1\n",
    "    word2idx['<sos>'] = 2\n",
    "    word2idx['<eos>'] = 3\n",
    "    return word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f30c0ec2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:39:31.198973Z",
     "start_time": "2024-07-27T19:39:31.195058Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # Encoder\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "\n",
    "    # Decoder initialization without an SOS token\n",
    "    # The first input to the decoder could be an assumed blank token, often just zeros\n",
    "    decoder_input = torch.zeros((1, 1), dtype=torch.long)  # Assuming your vocab is zero-indexed\n",
    "    decoder_hidden = encoder_hidden  # Use the last hidden state from the encoder to start the decoder\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()  # Use model's own prediction as next input\n",
    "\n",
    "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "        # Check if decoder has generated the end of sequence, often by target length or a special condition\n",
    "        if di == target_length - 1:  # Simple condition assuming reaching the end of target tensor\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fe5e804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:32:10.105594Z",
     "start_time": "2024-07-27T19:32:10.103988Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collate function for padding\n",
    "def collate_fn(batch):\n",
    "    source_batch, target_batch = zip(*batch)\n",
    "    source_batch_padded = pad_sequence(source_batch, padding_value=vocab_en['<pad>'], batch_first=True)\n",
    "    target_batch_padded = pad_sequence(target_batch, padding_value=vocab_fr['<pad>'], batch_first=True)\n",
    "    return source_batch_padded, target_batch_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a14a700f37aee5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:32:10.107251Z",
     "start_time": "2024-07-27T19:32:10.106142Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8faf5e32ad685b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:32:10.109022Z",
     "start_time": "2024-07-27T19:32:10.107819Z"
    }
   },
   "outputs": [],
   "source": [
    "########################## TODO: USE DIFFERENT EMBEDDING MODELS #################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bf21853",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:32:10.111110Z",
     "start_time": "2024-07-27T19:32:10.109555Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_embeddings_and_create_index(path):\n",
    "    word_to_idx = {}\n",
    "    idx = 0\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            word_to_idx[word] = idx\n",
    "            idx += 1\n",
    "    return word_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "929a107a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:32:10.114856Z",
     "start_time": "2024-07-27T19:32:10.112676Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dataset preparation\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, source_sentences, target_sentences, source_vocab, target_vocab, tokenizer_source, tokenizer_target):\n",
    "        self.source_sentences = source_sentences\n",
    "        self.target_sentences = target_sentences\n",
    "        self.source_vocab = source_vocab\n",
    "        self.target_vocab = target_vocab\n",
    "        self.tokenizer_source = tokenizer_source\n",
    "        self.tokenizer_target = tokenizer_target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.source_sentences)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        source_sentence = [self.source_vocab[token] if token in self.source_vocab else self.source_vocab['<unk>'] for token in self.tokenizer_source(self.source_sentences.iloc[index])]\n",
    "        target_sentence = [self.target_vocab[token] if token in self.target_vocab else self.target_vocab['<unk>'] for token in self.tokenizer_target(self.target_sentences.iloc[index])]\n",
    "        return torch.tensor(source_sentence, dtype=torch.long), torch.tensor(target_sentence, dtype=torch.long)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cafce509",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:32:10.117597Z",
     "start_time": "2024-07-27T19:32:10.115422Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example GloVe embedding file path and embedding dimension\n",
    "\n",
    "def load_glove_embeddings(path: str, word2idx: Dict[str, int], embedding_dim: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Load GloVe embeddings from a specified file and align them with the given word index dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - path (str): The file path to the GloVe embeddings file.\n",
    "    - word2idx (Dict[str, int]): A dictionary mapping words to their corresponding indices. This dictionary defines\n",
    "      the position each word’s vector should occupy in the resulting embedding matrix.\n",
    "    - embedding_dim (int): The dimensionality of the GloVe vectors (e.g., 50, 100, 200, 300).\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: A tensor of shape (len(word2idx), embedding_dim) containing the GloVe vectors aligned according to word2idx.\n",
    "    \"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        # Initialize the embedding matrix with zeros\n",
    "        embeddings = np.zeros((len(word2idx), embedding_dim))\n",
    "        \n",
    "        # Process each line in the GloVe file\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            \n",
    "            # If the word is in the provided dictionary, update the corresponding row in embeddings\n",
    "            if word in word2idx.keys():\n",
    "                # Convert embedding values from strings to float32\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                # Place the vector in the correct index as per word2idx\n",
    "                embeddings[word2idx[word]] = vector\n",
    "    \n",
    "    # Convert the numpy array to a PyTorch tensor\n",
    "    return torch.from_numpy(embeddings)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c09042f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T20:44:48.576241Z",
     "start_time": "2024-07-27T20:44:48.569744Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size, pretrained_embeddings):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialize the Encoder with pre-trained embeddings and a GRU layer.\n",
    "\n",
    "        Parameters:\n",
    "            hidden_size (int): The number of features in the hidden state of the GRU.\n",
    "            pretrained_embeddings (torch.Tensor): A tensor containing the pre-trained word embeddings.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        # Ensure that the pretrained embeddings are of type float32\n",
    "        if pretrained_embeddings.dtype != torch.float32:\n",
    "            pretrained_embeddings = pretrained_embeddings.to(dtype=torch.float32)\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=False)\n",
    "        embed_size = pretrained_embeddings.shape[1]  # Embedding size is the second dimension of the embeddings tensor\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, batch_first=True).float()  # Ensure GRU is initialized as float32\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Forward pass of the encoder which processes the input sequence.\n",
    "\n",
    "        Parameters:\n",
    "            input (torch.Tensor): The input sequence tensor, which should be indexed by batch.\n",
    "\n",
    "        Returns:\n",
    "            hidden (torch.Tensor): The hidden state of the GRU, representing the encoded information of the input.\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input).float()  # Ensure embedding outputs float32\n",
    "        _, hidden = self.rnn(embedded)\n",
    "        return hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, output_size, pretrained_embeddings):\n",
    "        \"\"\"\n",
    "        Initialize the Decoder with pre-trained embeddings, a GRU layer, and a linear output layer.\n",
    "\n",
    "        Parameters:\n",
    "            embed_size (int): The size of each embedding vector.\n",
    "            hidden_size (int): The number of features in the hidden state of the GRU.\n",
    "            output_size (int): The size of the output vocabulary.\n",
    "            pretrained_embeddings (torch.Tensor): A tensor containing the pre-trained word embeddings.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        # Ensure that the pretrained embeddings are of type float32\n",
    "        if pretrained_embeddings.dtype != torch.float32:\n",
    "            pretrained_embeddings = pretrained_embeddings.to(dtype=torch.float32)\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=False)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, batch_first=True).float()  # Ensure GRU is initialized as float32\n",
    "        self.fc = nn.Linear(hidden_size, output_size).float()  # Ensure Linear is initialized as float32\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Forward pass of the decoder that processes one timestep of the sequence.\n",
    "\n",
    "        Parameters:\n",
    "            x (torch.Tensor): The input tensor for the current timestep.\n",
    "            hidden (torch.Tensor): The hidden state from the last timestep.\n",
    "\n",
    "        Returns:\n",
    "            predicted (torch.Tensor): The output logits for the next word in the sequence.\n",
    "            hidden (torch.Tensor): The updated hidden state.\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(x).float()  # Ensure embedding outputs float32\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        predicted = self.fc(output)\n",
    "        return predicted, hidden\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, source, target):\n",
    "\n",
    "        \"\"\"\n",
    "        Forward pass of the Seq2Seq model which processes the entire input and target sequence.\n",
    "\n",
    "        Parameters:\n",
    "            source (torch.Tensor): The input sequence tensor.\n",
    "            target (torch.Tensor): The target sequence tensor used during training.\n",
    "\n",
    "        Returns:\n",
    "            outputs (torch.Tensor): The output from the decoder for each step in the sequence.\n",
    "        \"\"\"\n",
    "        hidden = self.encoder(source)\n",
    "        outputs, _ = self.decoder(target, hidden)\n",
    "        return outputs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3f1cdd4a53b9ac02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T20:51:43.188623Z",
     "start_time": "2024-07-27T20:51:43.183695Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_1(model, sentence, source_vocab, target_vocab, tokenizer_source, tokenizer_target, max_length=50, device=\"cpu\"):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Tokenize the input sentence\n",
    "    tokens = tokenizer_source(sentence.lower())\n",
    "\n",
    "    # Convert tokens to indices\n",
    "    indices = [source_vocab.get(token, source_vocab['<unk>']) for token in tokens]\n",
    "    #print(f\"indices: {indices}\")\n",
    "    #print(f\"words: {[list(source_vocab.keys())[list(source_vocab.values()).index(idx)] for idx in indices]}\")\n",
    "    # Prepare the input tensor\n",
    "    input_tensor = torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    #print(f\"input tensor size: {input_tensor.size()}\")\n",
    "    # Pass through the encoder\n",
    "    with torch.no_grad():\n",
    "        encoder_hidden = model.encoder(input_tensor)\n",
    "\n",
    "    #print(f\"encoder hidden size: {encoder_hidden.size()}\")\n",
    "\n",
    "    # Initialize the decoder input and hidden state\n",
    "    decoder_input = torch.tensor([[target_vocab['<sos>']]], dtype=torch.long).to(device)\n",
    "    #print(f\"decoder input size: {decoder_input.size()}\")\n",
    "    decoder_hidden = encoder_hidden#.unsqueeze(0)  # Add batch dimension back\n",
    "    #print(f\"decoder hidden size: {decoder_hidden.size()}\")\n",
    "\n",
    "\n",
    "    # Generate the output sequence\n",
    "    output_tokens = []\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            decoder_output, decoder_hidden = model.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        next_token = topi.squeeze().item()\n",
    "\n",
    "        if next_token == target_vocab['<eos>']:\n",
    "            break\n",
    "\n",
    "        output_tokens.append(next_token)\n",
    "        decoder_input = topi.squeeze(0)#.detach()#.unsqueeze(0)\n",
    "\n",
    "    # Convert indices to tokens\n",
    "    output_sentence = [list(target_vocab.keys())[list(target_vocab.values()).index(idx)] for idx in output_tokens]\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "723d8561d02784ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T20:51:43.522727Z",
     "start_time": "2024-07-27T20:51:43.519280Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_2(model, sentence, source_vocab, target_vocab, tokenizer_source, tokenizer_target, device=\"cpu\"):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        source = torch.tensor([source_vocab[token] if token in source_vocab else source_vocab['<unk>'] for token in tokenizer_source(sentence)], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        target = torch.tensor([target_vocab['<sos>']], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        hidden = model.encoder(source)\n",
    "        outputs = []\n",
    "        for _ in range(20):  # Limit the length of the generated sequence\n",
    "            output, hidden = model.decoder(target, hidden)\n",
    "            output = output.squeeze(0)\n",
    "            topv, target = output.topk(1)\n",
    "            #target = topi.squeeze(0)#.detach()\n",
    "            if target.item() == target_vocab['<eos>']:\n",
    "                break\n",
    "            outputs.append(target.item())\n",
    "        translated = ' '.join([list(target_vocab.keys())[list(target_vocab.values()).index(idx)] for idx in outputs])\n",
    "        return translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32199614",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T20:44:49.675922Z",
     "start_time": "2024-07-27T20:44:49.673203Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(model, loader, optimizer, criterion, epochs=10, device=\"cpu\"):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for src, trg in loader:\n",
    "            # Move tensors to the correct device and ensure they are long type for indexing operations\n",
    "            src = src.to(device).long()  # Correct type for embedding layer\n",
    "            trg = trg.to(device).long()  # Correct type for embedding layer\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass: The decoder's input is all except the last word\n",
    "            output = model(src, trg[:, :-1])  \n",
    "            \n",
    "            # Since output will be in float (from linear layers, and GRU output), ensure it's float32 if not already\n",
    "            output = output.float()\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:, 1:].contiguous().view(-1)  # Target doesn't include the first <sos> token\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        average_loss = total_loss / len(loader)\n",
    "        print(predict_1(model, \"I am a student\", vocab_en, vocab_fr, tokenize_en, tokenize_fr, device=device))\n",
    "        print(predict_2(model, \"I am a book\", vocab_en, vocab_fr, tokenize_en, tokenize_fr, device=device))\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {average_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40c6f773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T20:51:13.852872Z",
     "start_time": "2024-07-27T20:44:50.553265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 1/10, Loss: 6.1300\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 2/10, Loss: 4.6537\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 3/10, Loss: 3.5119\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 4/10, Loss: 2.5370\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 5/10, Loss: 1.7940\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 6/10, Loss: 1.2575\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 7/10, Loss: 0.8825\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 8/10, Loss: 0.5968\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 9/10, Loss: 0.4043\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 10/10, Loss: 0.2856\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "vocab_size = 10000\n",
    "# TODO: Do we build vocab on the entire dataset or just the training set?\n",
    "#word2idx_pre_embeddings = load_embeddings_and_create_index('glove.6B/glove.6B.100d.txt') TODO remove\n",
    "vocab_en = build_vocab(english_data[\"text\"], vocab_size, tokenize_en)\n",
    "vocab_fr = build_vocab(french_data[\"text\"], vocab_size, tokenize_fr)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(english_data, french_data, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "embedding_dim = 100\n",
    "\n",
    "# Load embeddings\n",
    "vocab_embeddings_en = load_glove_embeddings('glove.6B/glove.6B.100d.txt', vocab_en, embedding_dim)\n",
    "vocab_embeddings_fr = load_glove_embeddings('glove.6B/glove.6B.100d.txt', vocab_fr, embedding_dim)\n",
    "\n",
    "# Model instantiation\n",
    "hidden_size = 1024\n",
    "encoder = Encoder(hidden_size=hidden_size, pretrained_embeddings=vocab_embeddings_en)\n",
    "decoder = Decoder(embed_size=embedding_dim, hidden_size=hidden_size, output_size=len(vocab_fr), pretrained_embeddings=vocab_embeddings_fr)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = CrossEntropyLoss(ignore_index=vocab_fr['<pad>']).to(device)  # Move the loss function to the device\n",
    "\n",
    "dataset = TranslationDataset(english_data['text'], french_data['text'], vocab_en, vocab_fr, tokenizer_source=tokenize_en, tokenizer_target=tokenize_fr)\n",
    "loader = DataLoader(dataset, batch_size=2, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "train(model, loader, optimizer, criterion, epochs=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ef4919fc15a71ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:56:09.161651Z",
     "start_time": "2024-07-27T19:56:09.156364Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b13af837",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T17:42:37.676456Z",
     "start_time": "2024-07-27T17:42:37.312828Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "GRU: Expected input to be 2D or 3D, got 1D instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m         translated \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([target_vocab[token] \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m outputs])\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m translated\n\u001b[0;32m---> 20\u001b[0m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI am a student\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_en\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_fr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenize_en\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenize_fr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model, sentence, source_vocab, target_vocab, tokenizer_source, tokenizer_target, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):  \u001b[38;5;66;03m# Limit the length of the generated sequence\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m     topv, topi \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mtopk(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 67\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mForward pass of the decoder that processes one timestep of the sequence.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    hidden (torch.Tensor): The updated hidden state.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# Ensure embedding outputs float32\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted, hidden\n",
      "File \u001b[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1104\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1102\u001b[0m batch_sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m-> 1104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGRU: Expected input to be 2D or 3D, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1105\u001b[0m is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m   1106\u001b[0m batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: GRU: Expected input to be 2D or 3D, got 1D instead"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9936c567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T20:51:47.492197Z",
     "start_time": "2024-07-27T20:51:47.232176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", les difficultés , le conseil et la commission ont défini le contexte permettant d' une manière parfaitement coordonnée . - le 20 - madame la présidente , je crois - et j ' en reviens aux premières paroles de la situation de leur propre pays des pays comme l'\n",
      ", nous avons des inquiétudes au sujet de certaines autres amendements qui ont pris votés . il faut bien les\n"
     ]
    }
   ],
   "source": [
    "print(predict_1(model, \"I am a student\", vocab_en, vocab_fr, tokenize_en, tokenize_fr, device=device))\n",
    "print(predict_2(model, \"I am a book\", vocab_en, vocab_fr, tokenize_en, tokenize_fr, device=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91116faeb477c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Metal)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
