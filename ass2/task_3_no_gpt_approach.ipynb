{
 "cells": [
  {
   "cell_type": "code",
   "id": "3b5d9883f748e844",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:50:11.779894Z",
     "start_time": "2024-07-29T20:50:11.712451Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import nltk\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from preprocessing_task_2 import prepare_data\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "7c99c4a6b38254c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T20:50:11.938468Z",
     "start_time": "2024-07-29T20:50:11.928329Z"
    }
   },
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "#!python3 -m spacy download en_core_web_sm\n",
    "#!python3 -m spacy download fr_core_news_sm"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/niclasstoffregen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/niclasstoffregen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "222dc7acd4ceed5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:05:34.558715Z",
     "start_time": "2024-07-29T21:05:28.818248Z"
    }
   },
   "source": [
    "####### LOADING AND PREPROCESSING #############\n",
    "english_data, french_data = prepare_data(fraction=0.1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niclasstoffregen/nlp_project/ass2/preprocessing_task_2.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_en['text'] = data_en['text'].apply(lambda x: re.sub(regex_pattern, '', x))\n",
      "/Users/niclasstoffregen/nlp_project/ass2/preprocessing_task_2.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_fr['text'] = data_fr['text'].apply(lambda x: re.sub(regex_pattern, '', x))\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "61a7669965faa00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:05:37.852961Z",
     "start_time": "2024-07-29T21:05:35.867136Z"
    }
   },
   "source": [
    "# Functions to tokenize data and build vocab\n",
    "spacy_fr = spacy.load('fr_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize_fr(text):\n",
    "    return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "def build_vocab(sentences, vocab_size, word_tokenize):\n",
    "    all_words = [word for sentence in sentences for word in word_tokenize(sentence)]\n",
    "    word_counts = Counter(all_words)\n",
    "    vocab = [word for word, _ in word_counts.most_common(vocab_size)]\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab, start=4)}\n",
    "    word2idx['<pad>'] = 0\n",
    "    word2idx['<unk>'] = 1\n",
    "    word2idx['<sos>'] = 2\n",
    "    word2idx['<eos>'] = 3\n",
    "    return word2idx"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "afb94199",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:05:38.505393Z",
     "start_time": "2024-07-29T21:05:38.504089Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "4fe5e804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:05:38.875485Z",
     "start_time": "2024-07-29T21:05:38.871483Z"
    }
   },
   "source": [
    "# Collate function for padding\n",
    "def collate_fn(batch):\n",
    "    source_batch, target_batch = zip(*batch)\n",
    "    source_batch_padded = pad_sequence(source_batch, padding_value=vocab_en['<pad>'], batch_first=True)\n",
    "    target_batch_padded = pad_sequence(target_batch, padding_value=vocab_fr['<pad>'], batch_first=True)\n",
    "    return source_batch_padded, target_batch_padded"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "929a107a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:05:39.609825Z",
     "start_time": "2024-07-29T21:05:39.607105Z"
    }
   },
   "source": [
    "# Dataset preparation\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, source_sentences, target_sentences, source_vocab, target_vocab, tokenizer_source, tokenizer_target):\n",
    "        self.source_sentences = source_sentences\n",
    "        self.target_sentences = target_sentences\n",
    "        self.source_vocab = source_vocab\n",
    "        self.target_vocab = target_vocab\n",
    "        self.tokenizer_source = tokenizer_source\n",
    "        self.tokenizer_target = tokenizer_target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.source_sentences)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        source_sentence = [self.source_vocab[token] if token in self.source_vocab else self.source_vocab['<unk>'] for token in self.tokenizer_source(self.source_sentences.iloc[index])]\n",
    "        target_sentence = [self.target_vocab[token] if token in self.target_vocab else self.target_vocab['<unk>'] for token in self.tokenizer_target(self.target_sentences.iloc[index])]\n",
    "        return torch.tensor(source_sentence, dtype=torch.long), torch.tensor(target_sentence, dtype=torch.long)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "cafce509",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:05:40.481029Z",
     "start_time": "2024-07-29T21:05:40.477443Z"
    }
   },
   "source": [
    "# Example GloVe embedding file path and embedding dimension\n",
    "\n",
    "def load_glove_embeddings(path: str, word2idx: Dict[str, int], embedding_dim: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Load GloVe embeddings from a specified file and align them with the given word index dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - path (str): The file path to the GloVe embeddings file.\n",
    "    - word2idx (Dict[str, int]): A dictionary mapping words to their corresponding indices. This dictionary defines\n",
    "      the position each wordâ€™s vector should occupy in the resulting embedding matrix.\n",
    "    - embedding_dim (int): The dimensionality of the GloVe vectors (e.g., 50, 100, 200, 300).\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: A tensor of shape (len(word2idx), embedding_dim) containing the GloVe vectors aligned according to word2idx.\n",
    "    \"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        # Initialize the embedding matrix with zeros\n",
    "        #embeddings = np.zeros((len(word2idx), embedding_dim))\n",
    "        #better approach: init with random \n",
    "        embeddings = np.random.uniform(-0.1, 0.1, (len(word2idx), embedding_dim))\n",
    "        # Process each line in the GloVe file\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            \n",
    "            # If the word is in the provided dictionary, update the corresponding row in embeddings\n",
    "            if word in word2idx.keys():\n",
    "                # Convert embedding values from strings to float32\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                # Place the vector in the correct index as per word2idx\n",
    "                embeddings[word2idx[word]] = vector\n",
    "            else:\n",
    "                pass\n",
    "    # Convert the numpy array to a PyTorch tensor\n",
    "    return torch.from_numpy(embeddings)\n",
    "\n",
    "\n",
    "\n",
    "def load_word2vec_embeddings(path, word2idx, embedding_dim):\n",
    "    embeddings = np.random.uniform(-0.1, 0.1, (len(word2idx), embedding_dim))\n",
    "    with open(path, 'r', encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            if word in word2idx:\n",
    "                try:\n",
    "                    vector = np.asarray(values[1:], dtype='float32')\n",
    "                    embeddings[word2idx[word]] = vector\n",
    "                except ValueError:\n",
    "                    print(f\"Error converting values for word: {word}\")\n",
    "                    continue\n",
    "    return torch.from_numpy(embeddings)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:06:38.282422Z",
     "start_time": "2024-07-29T21:06:38.164924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, pretrained_embeddings, hidden_dim, dropout, num_layers=1):\n",
    "        super().__init__()\n",
    "        if pretrained_embeddings.dtype != torch.float32:\n",
    "            pretrained_embeddings = pretrained_embeddings.to(dtype=torch.float32)\n",
    "        embedding_dim = pretrained_embeddings.shape[1]\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=False)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers=num_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src = [src length, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = [src length, batch size, embedding dim]\n",
    "        outputs, hidden = self.rnn(embedded)  # no cell state in GRU!\n",
    "        # outputs = [src length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # outputs are always from the top hidden layer\n",
    "        return hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, pretrained_embeddings, dropout, num_layers=1):\n",
    "        super().__init__()\n",
    "        if pretrained_embeddings.dtype != torch.float32:\n",
    "            pretrained_embeddings = pretrained_embeddings.to(dtype=torch.float32)\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=False)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim + hidden_dim, hidden_dim, num_layers=num_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(embedding_dim + hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, context):\n",
    "        # input = [batch size]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # context = [n layers * n directions, batch size, hidden dim]\n",
    "        # n layers and n directions in the decoder will both always be 1, therefore:\n",
    "        # hidden = [1, batch size, hidden dim]\n",
    "        # context = [1, batch size, hidden dim]\n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch size]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1, batch size, embedding dim]\n",
    "        emb_con = torch.cat((embedded, context), dim=2)\n",
    "        # emb_con = [1, batch size, embedding dim + hidden dim]\n",
    "        output, hidden = self.rnn(emb_con, hidden)\n",
    "        # output = [seq len, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        # output = [1, batch size, hidden dim]\n",
    "        # hidden = [1, batch size, hidden dim]\n",
    "        output = torch.cat(\n",
    "            (embedded.squeeze(0), hidden.squeeze(0), context.squeeze(0)), dim=1\n",
    "        )\n",
    "        # output = [batch size, embedding dim + hidden dim * 2]\n",
    "        prediction = self.fc_out(output)\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction, hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        assert (\n",
    "            encoder.hidden_dim == decoder.hidden_dim\n",
    "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        # last hidden state of the encoder is the context\n",
    "        context = self.encoder(src)\n",
    "        # context = [n layers * n directions, batch size, hidden dim]\n",
    "        # context also used as the initial hidden state of the decoder\n",
    "        hidden = context\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_length):\n",
    "            # insert input token embedding, previous hidden state and the context state\n",
    "            # receive output tensor (predictions) and new hidden state\n",
    "            output, hidden = self.decoder(input, hidden, context)\n",
    "            # output = [batch size, output dim]\n",
    "            # hidden = [1, batch size, hidden dim]\n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            # get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            # input = [batch size]\n",
    "        return outputs"
   ],
   "id": "655eea5436881da1",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "7b75f4d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:06:49.989861Z",
     "start_time": "2024-07-29T21:06:39.263787Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.nn import CrossEntropyLoss, Module\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Define your device based on the availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Define the vocabulary size and embedding dimension\n",
    "vocab_size = 10000\n",
    "\n",
    "\n",
    "# Build vocabularies based on the training set only\n",
    "X_train, X_test, y_train, y_test = train_test_split(english_data, french_data, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Building vocabularies using only the training data to prevent information leakage\n",
    "vocab_en = build_vocab(X_train[\"text\"], vocab_size, tokenize_en)\n",
    "vocab_fr = build_vocab(y_train[\"text\"], vocab_size, tokenize_fr)\n",
    "print(f\"size of english vocab {len(vocab_en)}, size of french vocab {len(vocab_fr)}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of english vocab 10004, size of french vocab 10004\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:47:53.752277Z",
     "start_time": "2024-07-29T21:47:53.704771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    source_tokenizer,\n",
    "    source_vocab,\n",
    "    target_vocab,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    "    max_output_length=25,\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sentence = sentence.lower()\n",
    "        if isinstance(sentence, str):\n",
    "            tokens = [token if token in source_vocab else \"<unk>\" for token in source_tokenizer(sentence) ]\n",
    "        else:\n",
    "            tokens = [token for token in sentence]\n",
    "        tokens = [sos_token] + tokens + [eos_token]\n",
    "        ids = [source_vocab[token] for token in tokens]\n",
    "        tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n",
    "        context = model.encoder(tensor)\n",
    "        hidden = context\n",
    "        inputs = [target_vocab[sos_token]]\n",
    "        for _ in range(max_output_length):\n",
    "            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
    "            output, hidden = model.decoder(inputs_tensor, hidden, context)\n",
    "            predicted_token = output.argmax(-1).item()\n",
    "            inputs.append(predicted_token)\n",
    "            if predicted_token == target_vocab[eos_token]:\n",
    "                break\n",
    "        tokens = [list(target_vocab.keys())[list(target_vocab.values()).index(idx)] for idx in inputs]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def train_fn(\n",
    "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for src, trg in tqdm(data_loader):\n",
    "        src = src.to(device).long().T\n",
    "        trg = trg.to(device).long().T\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "        # output = [trg length, batch size, trg vocab size]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "        #trg = trg[1:].view(-1)\n",
    "        trg = trg[1:].reshape(-1)\n",
    "        # trg = [(trg length - 1) * batch size]\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)\n",
    "\n",
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg in tqdm(data_loader):\n",
    "            src = src.to(device).long().T\n",
    "            trg = trg.to(device).long().T\n",
    "            # src = [src length, batch size]\n",
    "            # trg = [trg length, batch size]\n",
    "            output = model(src, trg, 0)  # turn off teacher forcing\n",
    "            # output = [trg length, batch size, trg vocab size]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "            #trg = trg[1:].view(-1)\n",
    "            trg = trg[1:].reshape(-1)\n",
    "            # trg = [(trg length - 1) * batch size]\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ],
   "id": "fbd0dfce88342105",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:49:37.511707Z",
     "start_time": "2024-07-29T21:49:37.468182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "def evaluate_bleu(model, data_loader, source_tokenizer, source_vocab, target_vocab,device, quick=False):\n",
    "    \"\"\"\n",
    "    Evaluate the BLEU score for a translation model.\n",
    "\n",
    "    Args:\n",
    "        model: The translation model (Seq2Seq).\n",
    "        data_loader: DataLoader for the dataset to evaluate.\n",
    "        source_vocab: Vocabulary for the source language.\n",
    "        target_vocab: Vocabulary for the target language.\n",
    "        tokenizer_source: Tokenization function for the source language.\n",
    "        tokenizer_target: Tokenization function for the target language.\n",
    "        device: Device to run the model on ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        float: The BLEU score for the dataset.\n",
    "        :param source_tokenizer: \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "    sos_token = \"<sos>\"\n",
    "    eos_token = \"<eos>\"\n",
    "    pad_token = \"<pad>\"\n",
    "    unkown_token = \"<unk>\"\n",
    "    \n",
    "    counter = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for source, target in tqdm(data_loader):\n",
    "            counter += 1\n",
    "            if quick and counter == 10:\n",
    "                break\n",
    "            # Process each sentence in the batch\n",
    "            for i in range(source.size(0)):\n",
    "                source_sentence = source[i]\n",
    "                target_sentence = target[i]\n",
    "\n",
    "                # Convert source tensor to sentence\n",
    "                src_sent = ' '.join([list(source_vocab.keys())[list(source_vocab.values()).index(idx)] for idx in source_sentence if idx not in [source_vocab[pad_token], source_vocab[unkown_token], source_vocab[sos_token], source_vocab[eos_token]]])\n",
    "                # Generate translation\n",
    "                translation = translate_sentence(src_sent, model, source_tokenizer, source_vocab, target_vocab, sos_token, eos_token, device=device)\n",
    "                \n",
    "                # Convert target tensor to actual sentence\n",
    "                ref_sent = [list(target_vocab.keys())[list(target_vocab.values()).index(idx)] for idx in target_sentence if idx not in [target_vocab[pad_token], target_vocab[unkown_token], target_vocab[sos_token], target_vocab[eos_token]]]\n",
    "                #print(f\"sentence: {src_sent}\")\n",
    "                #print(f\"reference: {ref_sent}\")\n",
    "                #print(f\"translation: {translation}\")\n",
    "                # Append to lists\n",
    "                hypotheses.append(translation.split())\n",
    "                references.append([ref_sent])\n",
    "\n",
    "    # Calculate BLEU score\n",
    "    return corpus_bleu(references, hypotheses)\n",
    "\n",
    "from rouge import Rouge\n",
    "\n",
    "def evaluate_rouge(model, data_loader, source_tokenizer, source_vocab, target_vocab, device, quick=False):\n",
    "    \"\"\"\n",
    "    Evaluate the ROUGE score for a translation model.\n",
    "\n",
    "    Args:\n",
    "        model: The translation model (Seq2Seq).\n",
    "        data_loader: DataLoader for the dataset to evaluate.\n",
    "        source_vocab: Vocabulary for the source language.\n",
    "        target_vocab: Vocabulary for the target language.\n",
    "        tokenizer_source: Tokenization function for the source language.\n",
    "        tokenizer_target: Tokenization function for the target language.\n",
    "        device: Device to run the model on ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the ROUGE-1, ROUGE-2, and ROUGE-L scores.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    rouge = Rouge()\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "    sos_token = \"<sos>\"\n",
    "    eos_token = \"<eos>\"\n",
    "    pad_token = \"<pad>\"\n",
    "    unkown_token = \"<unk>\"\n",
    "    counter = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for source, target in tqdm(data_loader):\n",
    "            counter += 1\n",
    "            if quick and counter == 10:\n",
    "                break\n",
    "            for i in range(source.size(0)):\n",
    "                source_sentence = source[i]\n",
    "                target_sentence = target[i]\n",
    "                # More readable version\n",
    "                src_sent = ' '.join(str(source_vocab.get(idx.item(), source_vocab[unkown_token])) for idx in source_sentence if idx not in [source_vocab[pad_token], source_vocab[unkown_token], source_vocab[sos_token], source_vocab[eos_token]])\n",
    "                translation = translate_sentence(src_sent, model, source_tokenizer, source_vocab, target_vocab, sos_token, eos_token, device=device)\n",
    "                ref_sent = ' '.join(str(target_vocab.get(idx.item(), target_vocab[unkown_token])) for idx in target_sentence if idx not in [target_vocab[pad_token], target_vocab[unkown_token], target_vocab[sos_token], target_vocab[eos_token]])                \n",
    "                hypotheses.append(translation)\n",
    "                references.append(ref_sent)\n",
    "\n",
    "    return rouge.get_scores(hypotheses, references, avg=True)"
   ],
   "id": "1941795168f71f7a",
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "0694bb52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:07:56.004591Z",
     "start_time": "2024-07-29T21:07:30.876713Z"
    }
   },
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "input_dim = len(vocab_en)\n",
    "output_dim = len(vocab_fr)\n",
    "hidden_dim = 512\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "\n",
    "#Load embeddings word2vec\n",
    "vocab_embeddings_en = load_word2vec_embeddings('word2vec/english.txt', vocab_en, embedding_dim)\n",
    "vocab_embeddings_fr = load_word2vec_embeddings('word2vec/france.txt', vocab_fr, embedding_dim)\n",
    "print(f\"size of english embeddings {vocab_embeddings_en.shape}, size of french embeddings {vocab_embeddings_fr.shape}\")\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    vocab_embeddings_en,\n",
    "    hidden_dim,\n",
    "    encoder_dropout,\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    embedding_dim,\n",
    "    hidden_dim,\n",
    "    vocab_embeddings_fr,\n",
    "    decoder_dropout,\n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "\n",
    "\n",
    "model.apply(init_weights)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")\n",
    "\n",
    "\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "criterion = CrossEntropyLoss(ignore_index=vocab_fr['<pad>']).to(device)\n",
    "\n",
    "# Create datasets for training and validation\n",
    "train_dataset = TranslationDataset(X_train['text'], y_train['text'], vocab_en, vocab_fr, tokenize_en, tokenize_fr)\n",
    "val_dataset = TranslationDataset(X_val['text'], y_val['text'], vocab_en, vocab_fr, tokenize_en, tokenize_fr)\n",
    "test_dataset = TranslationDataset(X_test['text'], y_test['text'], vocab_en, vocab_fr, tokenize_en, tokenize_fr)\n",
    "\n",
    "# Create DataLoaders for training and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, collate_fn=collate_fn)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting values for word: communautÃ©\n",
      "size of english embeddings torch.Size([10004, 100]), size of french embeddings torch.Size([10004, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 15,927,940 trainable parameters\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "9936c567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T21:39:43.378418Z",
     "start_time": "2024-07-29T21:07:57.871312Z"
    }
   },
   "source": [
    "\n",
    "n_epochs = 10\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "results = pd.DataFrame(columns=[\"epoch\", \"train_loss\", \"valid_loss\", \"train_ppl\", \"valid_ppl\", \"bleu\", \"rouge\"])\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = train_fn(\n",
    "        model,\n",
    "        train_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        clip,\n",
    "        teacher_forcing_ratio,\n",
    "        device,\n",
    "    )\n",
    "    valid_loss = evaluate_fn(\n",
    "        model,\n",
    "        val_loader,\n",
    "        criterion,\n",
    "        device,\n",
    "    )\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f\"no_gpt_approach-{epoch}.pt\")\n",
    "\n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")\n",
    "    translation = translate_sentence(\n",
    "        \"i am a student\",\n",
    "        model,\n",
    "        tokenize_en,\n",
    "        vocab_en,\n",
    "        vocab_fr,\n",
    "        sos_token,\n",
    "        eos_token,\n",
    "        device,\n",
    "    )\n",
    "    print(f\"Prediction: {translation}\")\n",
    "    bleu_score = evaluate_bleu(model, test_loader, tokenize_en, vocab_en, vocab_fr, device, quick=True)\n",
    "    print(f\"BLEU score: {bleu_score}\")\n",
    "    rouge_score = evaluate_rouge(model, test_loader, tokenize_en, vocab_en, vocab_fr, device, quick=True)\n",
    "    print(f\"ROUGE score: {rouge_score}\")\n",
    "    results.loc[-1] = {\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"valid_loss\": valid_loss,\n",
    "            \"train_ppl\": np.exp(train_loss),\n",
    "            \"valid_ppl\": np.exp(valid_loss),\n",
    "            \"bleu\": bleu_score,\n",
    "            \"rouge\": rouge_score\n",
    "        }\n",
    "    \n",
    "results.to_csv(\"reports/csv/no_gpt_approach_results.csv\", index=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3756/3756 [28:15<00:00,  2.21it/s]  \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1252/1252 [03:27<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.391 | Train PPL: 219.453\n",
      "\tValid Loss:   5.872 | Valid PPL: 354.812\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 33\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124mTrain Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m7.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | Train PPL: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnp\u001B[38;5;241m.\u001B[39mexp(train_loss)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m7.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124mValid Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalid_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m7.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | Valid PPL: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnp\u001B[38;5;241m.\u001B[39mexp(valid_loss)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m7.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 33\u001B[0m translation \u001B[38;5;241m=\u001B[39m \u001B[43mtranslate_sentence\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mi am a student\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtokenize_en\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvocab_en\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvocab_fr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlower\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m    \u001B[49m\u001B[43msos_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[43meos_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrediction: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtranslation\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     45\u001B[0m bleu_score \u001B[38;5;241m=\u001B[39m evaluate_bleu(model, test_loader, tokenize_en, vocab_en, vocab_fr, device)\n",
      "Cell \u001B[0;32mIn[26], line 20\u001B[0m, in \u001B[0;36mtranslate_sentence\u001B[0;34m(sentence, model, source_tokenizer, source_vocab, target_vocab, sos_token, eos_token, device, max_output_length)\u001B[0m\n\u001B[1;32m     18\u001B[0m     tokens \u001B[38;5;241m=\u001B[39m [token \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m sentence]\n\u001B[1;32m     19\u001B[0m tokens \u001B[38;5;241m=\u001B[39m [sos_token] \u001B[38;5;241m+\u001B[39m tokens \u001B[38;5;241m+\u001B[39m [eos_token]\n\u001B[0;32m---> 20\u001B[0m ids \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[43msource_vocab\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     21\u001B[0m tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mLongTensor(ids)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     22\u001B[0m context \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mencoder(tensor)\n",
      "Cell \u001B[0;32mIn[26], line 20\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     18\u001B[0m     tokens \u001B[38;5;241m=\u001B[39m [token \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m sentence]\n\u001B[1;32m     19\u001B[0m tokens \u001B[38;5;241m=\u001B[39m [sos_token] \u001B[38;5;241m+\u001B[39m tokens \u001B[38;5;241m+\u001B[39m [eos_token]\n\u001B[0;32m---> 20\u001B[0m ids \u001B[38;5;241m=\u001B[39m [\u001B[43msource_vocab\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m tokens]\n\u001B[1;32m     21\u001B[0m tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mLongTensor(ids)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     22\u001B[0m context \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mencoder(tensor)\n",
      "\u001B[0;31mKeyError\u001B[0m: True"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "a6826af2",
   "metadata": {},
   "source": [
    "#############################################################################################################"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bf900c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10004\n",
      "6906\n",
      "10004\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "# Example GloVe embedding file path and embedding dimension\n",
    "\n",
    "def check_missing_words_in_embeddings(path: str, word2idx: Dict[str, int], embedding_dim: int) -> torch.Tensor:\n",
    "    print(len(word2idx))\n",
    "    missing_word_counter = 0\n",
    "    \n",
    "    \n",
    "        \n",
    "    glove_words = set()\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        # Process each line in the GloVe file to collect all GloVe words\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            glove_words.add(word)\n",
    "    \n",
    "    for word in word2idx:\n",
    "        if word not in glove_words:\n",
    "            missing_word_counter+=1\n",
    "    \n",
    "\n",
    "    print(missing_word_counter)\n",
    "    # Convert the numpy array to a PyTorch tensor\n",
    "\n",
    "check_missing_words_in_embeddings('glove.6B/glove.6B.100d.txt', vocab_fr, embedding_dim)\n",
    "\n",
    "check_missing_words_in_embeddings('fasttext/cc.fr.300.vec', vocab_fr, 300) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1338acce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRelevant notes:\\nIf a word in your vocabulary (word2idx) doesnâ€™t exist in the GloVe or FastText embeddings file, \\nits embedding vector would not be updated and would remain as initially set. \\nGiven that you initialize the embeddings matrix with zeros, \\nany word not found in the pre-trained dataset would be represented by a zero vector. \\n\\nupdate not found in vocubulary words are initialized with random vector\\n\\n\\n'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Relevant notes:\n",
    "If a word in  the vocabulary (word2idx) doesnâ€™t exist in the GloVe or FastText embeddings file, \n",
    "its embedding vector would not be updated and would remain as initially set by a zero vector. \n",
    "\n",
    "update:\n",
    "not found in vocubulary words are initialized with random vector\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c763cc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 687,  124,    7,  149,    4,  377, 1420,  195,    5,    7,  149,   13,\n",
       "          926,  688,   66,  689,    9,   13,   50,   11,  452,   30,    4,  322,\n",
       "            8]),\n",
       " tensor([1479,   53,  265,   14,    7,  943,   46,  944,    4,   35,   37,   76,\n",
       "          197,    9,  714,    4,   35,   21,  579,  103, 1480,   93,   11,  266,\n",
       "            6]))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4338b0cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english:\n",
      " They need to see the political dimension working , to see that officials accept their responsibilities and that there is communication with the citizens .\n",
      "french:\n",
      " Ils ont besoin que la dimension politique fonctionne , qu' il y ait des responsabilitÃ©s , qu' une communication soit Ã©tablie avec les citoyens .\n"
     ]
    }
   ],
   "source": [
    "def get_key_by_value(dictionary, search_value):\n",
    "    for key, value in dictionary.items():\n",
    "        if value == search_value:\n",
    "            return key\n",
    "    return None  # If the value is not found, return None or raise an exception\n",
    "\n",
    "\n",
    "list_en= [ 687,  124,    7,  149,    4,  377, 1420,  195,    5,    7,  149,   13,\n",
    "          926,  688,   66,  689,    9,   13,   50,   11,  452,   30,    4,  322,\n",
    "            8]\n",
    "\n",
    "print(\"english:\")\n",
    "\n",
    "res= \"\"\n",
    "for i in list_en:\n",
    "    res= res + \" \"+  get_key_by_value(vocab_en, i)\n",
    "print(res)\n",
    "    \n",
    "\n",
    "##########\n",
    "\n",
    "\n",
    "list_fr= [1479,   53,  265,   14,    7,  943,   46,  944,    4,   35,   37,   76,\n",
    "          197,    9,  714,    4,   35,   21,  579,  103, 1480,   93,   11,  266,\n",
    "            6]\n",
    "\n",
    "print(\"french:\")\n",
    "\n",
    "res= \"\"\n",
    "for i in list_fr:\n",
    "    res= res + \" \"+  get_key_by_value(vocab_fr, i)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "75b107fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resumption of the session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I declare resumed the session of the European ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although, as you will have seen, the dreaded '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You have requested a debate on this subject in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the meantime, I should like to observe a mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>There is still a need to tighten up in the are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>This is especially necessary in relation to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>As Liberals and Greens, we clearly have differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Mr President, Commissioner, there are just two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Are state aid to business or inter-company agr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0                            Resumption of the session\n",
       "1    I declare resumed the session of the European ...\n",
       "2    Although, as you will have seen, the dreaded '...\n",
       "3    You have requested a debate on this subject in...\n",
       "4    In the meantime, I should like to observe a mi...\n",
       "..                                                 ...\n",
       "995  There is still a need to tighten up in the are...\n",
       "996  This is especially necessary in relation to th...\n",
       "997  As Liberals and Greens, we clearly have differ...\n",
       "998  Mr President, Commissioner, there are just two...\n",
       "999  Are state aid to business or inter-company agr...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b702f6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reprise de la session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Je dÃ©clare reprise la session du Parlement eur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comme vous avez pu le constater, le grand \"bog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vous avez souhaitÃ© un dÃ©bat Ã  ce sujet dans le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>En attendant, je souhaiterais, comme un certai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Cela se trouvait dans la communication du mois...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>N'allez pas croire qu'il y ait eu une quelconq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Je pensais que ce dossier Ã©tait bien plus avancÃ©.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Je suis dÃ©solÃ©e.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Ne croyez pas que la date a Ã©tÃ© choisie en fon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0                                  Reprise de la session\n",
       "1      Je dÃ©clare reprise la session du Parlement eur...\n",
       "2      Comme vous avez pu le constater, le grand \"bog...\n",
       "3      Vous avez souhaitÃ© un dÃ©bat Ã  ce sujet dans le...\n",
       "4      En attendant, je souhaiterais, comme un certai...\n",
       "...                                                  ...\n",
       "99995  Cela se trouvait dans la communication du mois...\n",
       "99996  N'allez pas croire qu'il y ait eu une quelconq...\n",
       "99997  Je pensais que ce dossier Ã©tait bien plus avancÃ©.\n",
       "99998                                   Je suis dÃ©solÃ©e.\n",
       "99999  Ne croyez pas que la date a Ã©tÃ© choisie en fon...\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9ab91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a31a9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(english_data, french_data, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)  # 0.25 x 0.8 = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "09aec1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Please rise, then, for this minute' s silence.\""
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"text\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2e5898fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Je vous invite Ã  vous lever pour cette minute de silence.'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[\"text\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e60273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47eeeca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "nlp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
