{
 "cells": [
  {
   "cell_type": "code",
   "id": "3b5d9883f748e844",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T22:11:56.641263Z",
     "start_time": "2024-07-27T22:11:55.139580Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import nltk\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from preprocessing_task_2 import prepare_data\n",
    "import spacy\n",
    "from collections import Counter"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "7c99c4a6b38254c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T22:12:06.004012Z",
     "start_time": "2024-07-27T22:11:56.642447Z"
    }
   },
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "!python3 -m spacy download fr_core_news_sm"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/niclasstoffregen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/niclasstoffregen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m10.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\r\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\r\n",
      "Requirement already satisfied: jinja2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\r\n",
      "Requirement already satisfied: setuptools in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (70.1.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\r\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.6.2)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\r\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\r\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\r\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\r\n",
      "Requirement already satisfied: wrapt in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n",
      "Collecting fr-core-news-sm==3.7.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m16.3/16.3 MB\u001B[0m \u001B[31m9.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from fr-core-news-sm==3.7.0) (3.7.5)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.5)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.3)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.4.1)\r\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.12.3)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.4)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.32.3)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.8.2)\r\n",
      "Requirement already satisfied: jinja2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.4)\r\n",
      "Requirement already satisfied: setuptools in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (70.1.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (24.1)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.4)\r\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.2.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.12.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2024.6.2)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.5)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (13.7.1)\r\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.18.1)\r\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (7.0.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.5)\r\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.2.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.18.0)\r\n",
      "Requirement already satisfied: wrapt in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.16.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "222dc7acd4ceed5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T22:12:14.808371Z",
     "start_time": "2024-07-27T22:12:06.005335Z"
    }
   },
   "source": [
    "####### LOADING AND PREPROCESSING #############\n",
    "english_data, french_data = prepare_data(fraction=0.1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niclasstoffregen/nlp_project/ass2/preprocessing_task_2.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data_en = data_en[mask]\n",
      "/Users/niclasstoffregen/nlp_project/ass2/preprocessing_task_2.py:26: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data_fr = data_fr[mask]\n",
      "/Users/niclasstoffregen/nlp_project/ass2/preprocessing_task_2.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_en['text'] = data_en['text'].apply(lambda x: re.sub(regex_pattern, '', x))\n",
      "/Users/niclasstoffregen/nlp_project/ass2/preprocessing_task_2.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_fr['text'] = data_fr['text'].apply(lambda x: re.sub(regex_pattern, '', x))\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "61a7669965faa00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T22:12:17.005383Z",
     "start_time": "2024-07-27T22:12:14.809040Z"
    }
   },
   "source": [
    "# Functions to tokenize data and build vocab\n",
    "spacy_fr = spacy.load('fr_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize_fr(text):\n",
    "    return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "def build_vocab(sentences, vocab_size, word_tokenize):\n",
    "    all_words = [word for sentence in sentences for word in word_tokenize(sentence)]\n",
    "    word_counts = Counter(all_words)\n",
    "    vocab = [word for word, _ in word_counts.most_common(vocab_size)]\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab, start=4)}\n",
    "    word2idx['<pad>'] = 0\n",
    "    word2idx['<unk>'] = 1\n",
    "    word2idx['<sos>'] = 2\n",
    "    word2idx['<eos>'] = 3\n",
    "    return word2idx"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "4fe5e804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T22:12:17.008919Z",
     "start_time": "2024-07-27T22:12:17.007052Z"
    }
   },
   "source": [
    "# Collate function for padding\n",
    "def collate_fn(batch):\n",
    "    source_batch, target_batch = zip(*batch)\n",
    "    source_batch_padded = pad_sequence(source_batch, padding_value=vocab_en['<pad>'], batch_first=True)\n",
    "    target_batch_padded = pad_sequence(target_batch, padding_value=vocab_fr['<pad>'], batch_first=True)\n",
    "    return source_batch_padded, target_batch_padded"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "2a14a700f37aee5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T22:12:17.010760Z",
     "start_time": "2024-07-27T22:12:17.009467Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "a8faf5e32ad685b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T22:12:17.012800Z",
     "start_time": "2024-07-27T22:12:17.011425Z"
    }
   },
   "source": [
    "########################## TODO: USE DIFFERENT EMBEDDING MODELS #################\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "1bf21853",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T22:12:17.015038Z",
     "start_time": "2024-07-27T22:12:17.013345Z"
    }
   },
   "source": [
    "\n",
    "def load_embeddings_and_create_index(path):\n",
    "    word_to_idx = {}\n",
    "    idx = 0\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            word_to_idx[word] = idx\n",
    "            idx += 1\n",
    "    return word_to_idx\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "929a107a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T22:12:17.017700Z",
     "start_time": "2024-07-27T22:12:17.015595Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Dataset preparation\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, source_sentences, target_sentences, source_vocab, target_vocab, tokenizer_source, tokenizer_target):\n",
    "        self.source_sentences = source_sentences\n",
    "        self.target_sentences = target_sentences\n",
    "        self.source_vocab = source_vocab\n",
    "        self.target_vocab = target_vocab\n",
    "        self.tokenizer_source = tokenizer_source\n",
    "        self.tokenizer_target = tokenizer_target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.source_sentences)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        source_sentence = [self.source_vocab[token] if token in self.source_vocab else self.source_vocab['<unk>'] for token in self.tokenizer_source(self.source_sentences.iloc[index])]\n",
    "        target_sentence = [self.target_vocab[token] if token in self.target_vocab else self.target_vocab['<unk>'] for token in self.tokenizer_target(self.target_sentences.iloc[index])]\n",
    "        return torch.tensor(source_sentence, dtype=torch.long), torch.tensor(target_sentence, dtype=torch.long)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "cafce509",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T22:12:17.020345Z",
     "start_time": "2024-07-27T22:12:17.018298Z"
    }
   },
   "source": [
    "# Example GloVe embedding file path and embedding dimension\n",
    "\n",
    "def load_glove_embeddings(path: str, word2idx: Dict[str, int], embedding_dim: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Load GloVe embeddings from a specified file and align them with the given word index dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - path (str): The file path to the GloVe embeddings file.\n",
    "    - word2idx (Dict[str, int]): A dictionary mapping words to their corresponding indices. This dictionary defines\n",
    "      the position each word’s vector should occupy in the resulting embedding matrix.\n",
    "    - embedding_dim (int): The dimensionality of the GloVe vectors (e.g., 50, 100, 200, 300).\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: A tensor of shape (len(word2idx), embedding_dim) containing the GloVe vectors aligned according to word2idx.\n",
    "    \"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        # Initialize the embedding matrix with zeros\n",
    "        embeddings = np.zeros((len(word2idx), embedding_dim))\n",
    "        \n",
    "        # Process each line in the GloVe file\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            \n",
    "            # If the word is in the provided dictionary, update the corresponding row in embeddings\n",
    "            if word in word2idx.keys():\n",
    "                # Convert embedding values from strings to float32\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                # Place the vector in the correct index as per word2idx\n",
    "                embeddings[word2idx[word]] = vector\n",
    "    \n",
    "    # Convert the numpy array to a PyTorch tensor\n",
    "    return torch.from_numpy(embeddings)\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "c09042f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T22:12:17.024610Z",
     "start_time": "2024-07-27T22:12:17.020930Z"
    }
   },
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size, pretrained_embeddings):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialize the Encoder with pre-trained embeddings and a GRU layer.\n",
    "\n",
    "        Parameters:\n",
    "            hidden_size (int): The number of features in the hidden state of the GRU.\n",
    "            pretrained_embeddings (torch.Tensor): A tensor containing the pre-trained word embeddings.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        # Ensure that the pretrained embeddings are of type float32\n",
    "        if pretrained_embeddings.dtype != torch.float32:\n",
    "            pretrained_embeddings = pretrained_embeddings.to(dtype=torch.float32)\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=False)\n",
    "        embed_size = pretrained_embeddings.shape[1]  # Embedding size is the second dimension of the embeddings tensor\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, batch_first=True).float()  # Ensure GRU is initialized as float32\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Forward pass of the encoder which processes the input sequence.\n",
    "\n",
    "        Parameters:\n",
    "            input (torch.Tensor): The input sequence tensor, which should be indexed by batch.\n",
    "\n",
    "        Returns:\n",
    "            hidden (torch.Tensor): The hidden state of the GRU, representing the encoded information of the input.\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input).float()  # Ensure embedding outputs float32\n",
    "        _, hidden = self.rnn(embedded)\n",
    "        return hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, output_size, pretrained_embeddings):\n",
    "        \"\"\"\n",
    "        Initialize the Decoder with pre-trained embeddings, a GRU layer, and a linear output layer.\n",
    "\n",
    "        Parameters:\n",
    "            embed_size (int): The size of each embedding vector.\n",
    "            hidden_size (int): The number of features in the hidden state of the GRU.\n",
    "            output_size (int): The size of the output vocabulary.\n",
    "            pretrained_embeddings (torch.Tensor): A tensor containing the pre-trained word embeddings.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        # Ensure that the pretrained embeddings are of type float32\n",
    "        if pretrained_embeddings.dtype != torch.float32:\n",
    "            pretrained_embeddings = pretrained_embeddings.to(dtype=torch.float32)\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=False)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, batch_first=True).float()  # Ensure GRU is initialized as float32\n",
    "        self.fc = nn.Linear(hidden_size, output_size).float()  # Ensure Linear is initialized as float32\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Forward pass of the decoder that processes one timestep of the sequence.\n",
    "\n",
    "        Parameters:\n",
    "            x (torch.Tensor): The input tensor for the current timestep.\n",
    "            hidden (torch.Tensor): The hidden state from the last timestep.\n",
    "\n",
    "        Returns:\n",
    "            predicted (torch.Tensor): The output logits for the next word in the sequence.\n",
    "            hidden (torch.Tensor): The updated hidden state.\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(x).float()  # Ensure embedding outputs float32\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        predicted = self.fc(output)\n",
    "        return predicted, hidden\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, source, target):\n",
    "\n",
    "        \"\"\"\n",
    "        Forward pass of the Seq2Seq model which processes the entire input and target sequence.\n",
    "\n",
    "        Parameters:\n",
    "            source (torch.Tensor): The input sequence tensor.\n",
    "            target (torch.Tensor): The target sequence tensor used during training.\n",
    "\n",
    "        Returns:\n",
    "            outputs (torch.Tensor): The output from the decoder for each step in the sequence.\n",
    "        \"\"\"\n",
    "        hidden = self.encoder(source)\n",
    "        outputs, _ = self.decoder(target, hidden)\n",
    "        return outputs\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T22:12:17.027598Z",
     "start_time": "2024-07-27T22:12:17.025044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_1(model, sentence, source_vocab, target_vocab, tokenizer_source, tokenizer_target, max_length=50, device=\"cpu\"):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Tokenize the input sentence\n",
    "    tokens = tokenizer_source(sentence.lower())\n",
    "\n",
    "    # Convert tokens to indices\n",
    "    indices = [source_vocab.get(token, source_vocab['<unk>']) for token in tokens]\n",
    "    # Prepare the input tensor\n",
    "    input_tensor = torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(device) \n",
    "    \n",
    "    # Pass through the encoder\n",
    "    with torch.no_grad():\n",
    "        encoder_hidden = model.encoder(input_tensor)\n",
    "\n",
    "    #print(f\"encoder hidden size: {encoder_hidden.size()}\")\n",
    "\n",
    "    # Initialize the decoder input and hidden state\n",
    "    decoder_input = torch.tensor([[target_vocab['<sos>']]], dtype=torch.long).to(device)\n",
    "    #print(f\"decoder input size: {decoder_input.size()}\")\n",
    "    decoder_hidden = encoder_hidden#.unsqueeze(0)  # Add batch dimension back\n",
    "    #print(f\"decoder hidden size: {decoder_hidden.size()}\")\n",
    "\n",
    "\n",
    "    # Generate the output sequence\n",
    "    output_tokens = []\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            decoder_output, decoder_hidden = model.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        next_token = topi.squeeze().item()\n",
    "\n",
    "        if next_token == target_vocab['<eos>']:\n",
    "            break\n",
    "\n",
    "        output_tokens.append(next_token)\n",
    "        decoder_input = topi.squeeze(0)#.detach()#.unsqueeze(0)\n",
    "\n",
    "    # Convert indices to tokens\n",
    "    output_sentence = [list(target_vocab.keys())[list(target_vocab.values()).index(idx)] for idx in output_tokens]\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ],
   "id": "3f1cdd4a53b9ac02",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T22:12:17.030186Z",
     "start_time": "2024-07-27T22:12:17.028016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_2(model, sentence, source_vocab, target_vocab, tokenizer_source, tokenizer_target, device=\"cpu\"):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        source = torch.tensor([source_vocab[token] if token in source_vocab else source_vocab['<unk>'] for token in tokenizer_source(sentence.lower())], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        target = torch.tensor([target_vocab['<sos>']], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        hidden = model.encoder(source)\n",
    "        outputs = []\n",
    "        for _ in range(20):  # Limit the length of the generated sequence\n",
    "            output, hidden = model.decoder(target, hidden)\n",
    "            output = output.squeeze(0)\n",
    "            topv, target = output.topk(1)\n",
    "            #target = topi.squeeze(0)#.detach()\n",
    "            if target.item() == target_vocab['<eos>']:\n",
    "                break\n",
    "            outputs.append(target.item())\n",
    "        translated = ' '.join([list(target_vocab.keys())[list(target_vocab.values()).index(idx)] for idx in outputs])\n",
    "        return translated"
   ],
   "id": "723d8561d02784ef",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "32199614",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T22:12:17.034298Z",
     "start_time": "2024-07-27T22:12:17.032019Z"
    }
   },
   "source": [
    "\n",
    "def train(model, loader, optimizer, criterion, epochs=10, device=\"cpu\"):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for src, trg in loader:\n",
    "            # Move tensors to the correct device and ensure they are long type for indexing operations\n",
    "            src = src.to(device).long()  # Correct type for embedding layer\n",
    "            trg = trg.to(device).long()  # Correct type for embedding layer\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass: The decoder's input is all except the last word\n",
    "            output = model(src, trg[:, :-1])  \n",
    "            \n",
    "            # Since output will be in float (from linear layers, and GRU output), ensure it's float32 if not already\n",
    "            output = output.float()\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:, 1:].contiguous().view(-1)  # Target doesn't include the first <sos> token\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        average_loss = total_loss / len(loader)\n",
    "        print(predict_1(model, \"I am a student\", vocab_en, vocab_fr, tokenize_en, tokenize_fr, device=device))\n",
    "        print(predict_2(model, \"I am a book\", vocab_en, vocab_fr, tokenize_en, tokenize_fr, device=device))\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {average_loss:.4f}')"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "40c6f773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T22:53:39.601586Z",
     "start_time": "2024-07-27T22:12:17.034714Z"
    }
   },
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(english_data, french_data, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "vocab_size = 10000\n",
    "vocab_en = build_vocab(X_train[\"text\"], vocab_size, tokenize_en)\n",
    "vocab_fr = build_vocab(y_train[\"text\"], vocab_size, tokenize_fr)\n",
    "print(f\"English vocab size: {len(vocab_en)}, French vocab size: {len(vocab_fr)}\")\n",
    "embedding_dim = 100\n",
    "\n",
    "# Load embeddings TODO: use same or different embeddings for source and target languages?\n",
    "vocab_embeddings_en = load_glove_embeddings('glove.6B/glove.6B.100d.txt', vocab_en, embedding_dim)\n",
    "vocab_embeddings_fr = load_glove_embeddings('glove.6B/glove.6B.100d.txt', vocab_fr, embedding_dim)\n",
    "\n",
    "# Model instantiation\n",
    "hidden_size = 1024\n",
    "encoder = Encoder(hidden_size=hidden_size, pretrained_embeddings=vocab_embeddings_en)\n",
    "decoder = Decoder(embed_size=embedding_dim, hidden_size=hidden_size, output_size=len(vocab_fr), pretrained_embeddings=vocab_embeddings_fr)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = CrossEntropyLoss(ignore_index=vocab_fr['<pad>']).to(device)  # Move the loss function to the device\n",
    "\n",
    "# Use training data for the dataset\n",
    "train_dataset = TranslationDataset(X_train['text'], y_train['text'], vocab_en, vocab_fr, tokenizer_source=tokenize_en, tokenizer_target=tokenize_fr)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_fn)  # Increased batch size\n",
    "\n",
    "# Validation DataLoader\n",
    "val_dataset = TranslationDataset(X_val['text'], y_val['text'], vocab_en, vocab_fr, tokenizer_source=tokenize_en, tokenizer_target=tokenize_fr)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, collate_fn=collate_fn)  # Increased batch size\n",
    "\n",
    "\n",
    "train(model, train_loader, optimizer, criterion, epochs=10, device=device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocab size: 10004, French vocab size: 10004\n",
      ", il est important de la compétence de la commission de la pêche et de la commission . - et je pense que nous avons tous conscients de la commission de l' industrie , du commerce extérieur , de la recherche et de la politique de l' énergie , de\n",
      ", il est important de la commission de la pêche et de la commission . - et je pense que\n",
      "Epoch 1/10, Loss: 4.6885\n",
      ", en ce qui concerne la question de la commission , je voudrais rappeler que la commission a approuvé une proposition de règlement . je pense que le parlement européen a été <unk> , et je pense que le parlement européen a été <unk> , et je pense que le\n",
      ", je voudrais dire que la commission a approuvé une proposition de règlement . je pense que le parlement européen\n",
      "Epoch 2/10, Loss: 3.8403\n",
      ", monsieur le commissaire , le rapport de mme palacio <unk> , qui est présenté au parlement européen , qui est très important pour la deuxième lecture . je voudrais cependant poser une question complémentaire : il est très important que l' union européenne devrait avoir une influence positive ,\n",
      ", je voudrais dire que l' on ne peut pas couper les principes de la politique agricole commune , et\n",
      "Epoch 3/10, Loss: 3.4048\n",
      ", il y a des obstacles à la mobilité des étudiants , et nous devons aussi dire que les choses doivent être libres . il faut aussi pouvoir apporter une aide tangible . ce n’ est pas le cas . il s’ agit d’ un processus d’ apprentissage . il\n",
      ", il ne suffit pas de ne pas avoir de bonnes espoirs pour les banques centrales nucléaires . mais cela\n",
      "Epoch 4/10, Loss: 3.0113\n",
      ", il y a des <unk> , mais il s’ agit d’ un <unk> . il s’ agit d’ une impasse . il est nécessaire d’ arriver à un accord sur le fait que la communauté internationale dans des pays comme la pologne , la hongrie , la pologne et\n",
      ", il faut avoir une autorité morale à la commission , en particulier dans le domaine des dispositifs médicaux ,\n",
      "Epoch 5/10, Loss: 2.6875\n",
      ", monsieur le commissaire , nous devons faire en sorte que les mécanismes de recherche soient adoptés . cela ne signifie pas que le conseil européen de la commission a proposé une proposition . il est juste que les principes soient <unk> pour les incorporer dans les produits biologiques .\n",
      ", il faut aller plus loin que les régions et les pays candidats , et en particulier les pays en\n",
      "Epoch 6/10, Loss: 2.4523\n",
      ", monsieur le président , je voudrais vous demander si vous me <unk> . je vous demande , monsieur le président , de prendre contact avec la commission européenne et de votre discours de continuer à collaborer avec la commission européenne , en particulier en ce qui concerne le calendrier\n",
      ", monsieur le président , je voudrais dire que la nouvelle approche de la commission est un aspect essentiel pour\n",
      "Epoch 7/10, Loss: 2.2839\n",
      ", monsieur le commissaire , vous dites que vous avez agi tout à fait prioritaire . je vous remercie , monsieur le commissaire nielson . - je vous remercie , monsieur le président . - monsieur le président , pour votre discours , en tant que seule , pour la\n",
      ", monsieur le président , la seule manière d' éviter les guerres biologiques et biologiques les droits économiques et sociaux\n",
      "Epoch 8/10, Loss: 2.1603\n",
      ", monsieur le commissaire , nous avons tenu compte tenu de la situation au moyen-orient . il est indispensable d' affronter la cogénération dans le domaine des sciences de l' énergie . - in de l' éducation , de nouvelles femmes et des enfants - éducation et d' éducation ,\n",
      ", monsieur le président , la seule manière d' aborder ces questions lors de la stratégie de lisbonne , mais\n",
      "Epoch 9/10, Loss: 2.0652\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 36\u001B[0m\n\u001B[1;32m     32\u001B[0m val_dataset \u001B[38;5;241m=\u001B[39m TranslationDataset(X_val[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m], y_val[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m], vocab_en, vocab_fr, tokenizer_source\u001B[38;5;241m=\u001B[39mtokenize_en, tokenizer_target\u001B[38;5;241m=\u001B[39mtokenize_fr)\n\u001B[1;32m     33\u001B[0m val_loader \u001B[38;5;241m=\u001B[39m DataLoader(val_dataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, collate_fn\u001B[38;5;241m=\u001B[39mcollate_fn)  \u001B[38;5;66;03m# Increased batch size\u001B[39;00m\n\u001B[0;32m---> 36\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[13], line 14\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, loader, optimizer, criterion, epochs, device)\u001B[0m\n\u001B[1;32m     11\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Forward pass: The decoder's input is all except the last word\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrg\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m  \n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Since output will be in float (from linear layers, and GRU output), ensure it's float32 if not already\u001B[39;00m\n\u001B[1;32m     17\u001B[0m output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mfloat()\n",
      "File \u001B[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[10], line 89\u001B[0m, in \u001B[0;36mSeq2Seq.forward\u001B[0;34m(self, source, target)\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, source, target):\n\u001B[1;32m     79\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;124;03m    Forward pass of the Seq2Seq model which processes the entire input and target sequence.\u001B[39;00m\n\u001B[1;32m     81\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;124;03m        outputs (torch.Tensor): The output from the decoder for each step in the sequence.\u001B[39;00m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 89\u001B[0m     hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     90\u001B[0m     outputs, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(target, hidden)\n\u001B[1;32m     91\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[10], line 30\u001B[0m, in \u001B[0;36mEncoder.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;124;03mForward pass of the encoder which processes the input sequence.\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;124;03m    hidden (torch.Tensor): The hidden state of the GRU, representing the encoded information of the input.\u001B[39;00m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     29\u001B[0m embedded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding(\u001B[38;5;28minput\u001B[39m)\u001B[38;5;241m.\u001B[39mfloat()  \u001B[38;5;66;03m# Ensure embedding outputs float32\u001B[39;00m\n\u001B[0;32m---> 30\u001B[0m _, hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43membedded\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m hidden\n",
      "File \u001B[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1133\u001B[0m, in \u001B[0;36mGRU.forward\u001B[0;34m(self, input, hx)\u001B[0m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_forward_args(\u001B[38;5;28minput\u001B[39m, hx, batch_sizes)\n\u001B[1;32m   1132\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1133\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgru\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1134\u001B[0m \u001B[43m                     \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_first\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1135\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1136\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mgru(\u001B[38;5;28minput\u001B[39m, batch_sizes, hx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_weights, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias,\n\u001B[1;32m   1137\u001B[0m                      \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "9ef4919fc15a71ca",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b13af837",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9936c567",
   "metadata": {},
   "source": [
    "print(predict_1(model, \"I am a student\", vocab_en, vocab_fr, tokenize_en, tokenize_fr, device=device))\n",
    "print(predict_2(model, \"I am a book\", vocab_en, vocab_fr, tokenize_en, tokenize_fr, device=device))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def evaluate_with_bleu(model, loader, criterion, target_vocab, device=\"cpu\"):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    total_bleu_score = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, trg in loader:\n",
    "            src = src.to(device).long()  # Move source to device and ensure it's long type\n",
    "            trg = trg.to(device).long()  # Move target to device and ensure it's long type\n",
    "\n",
    "            # Forward pass: The decoder's input is all except the last word\n",
    "            output = model(src, trg[:, :-1])\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:, 1:].contiguous().view(-1)  # Target doesn't include the first <sos> token\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            total_loss += loss.item() * src.size(0)\n",
    "            total_samples += src.size(0)\n",
    "\n",
    "            # Calculate BLEU score\n",
    "            output = output.view(src.size(0), -1, output_dim)\n",
    "            for i in range(src.size(0)):\n",
    "                pred_indices = output[i].argmax(dim=1).tolist()\n",
    "                target_indices = trg[i].tolist()\n",
    "                pred_sentence = [list(target_vocab.keys())[list(target_vocab.values()).index(idx)] for idx in pred_indices if idx in target_vocab.values()]\n",
    "                target_sentence = [list(target_vocab.keys())[list(target_vocab.values()).index(idx)] for idx in target_indices if idx in target_vocab.values()]\n",
    "                total_bleu_score += sentence_bleu([target_sentence], pred_sentence)\n",
    "\n",
    "    average_loss = total_loss / total_samples\n",
    "    average_bleu_score = total_bleu_score / total_samples\n",
    "    return average_loss, average_bleu_score"
   ],
   "id": "4c91116faeb477c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Assuming `val_loader` is the DataLoader for the validation set\n",
    "val_loss, val_bleu = evaluate_with_bleu(model, val_loader, criterion, vocab_fr, device=device)\n",
    "print(f'Validation Loss: {val_loss:.4f}, Validation BLEU Score: {val_bleu:.4f}')"
   ],
   "id": "1290a88e886e1e47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5f5534a0b5dec83e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "nlp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
