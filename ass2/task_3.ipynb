{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5d9883f748e844",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:31:49.602734Z",
     "start_time": "2024-07-27T19:31:47.986253Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import nltk\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from preprocessing_task_2 import prepare_data\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c99c4a6b38254c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:31:59.611798Z",
     "start_time": "2024-07-27T19:31:49.603784Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/niclasstoffregen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/niclasstoffregen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m6.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\r\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\r\n",
      "Requirement already satisfied: jinja2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\r\n",
      "Requirement already satisfied: setuptools in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (70.1.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\r\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.6.2)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\r\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\r\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\r\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\r\n",
      "Requirement already satisfied: wrapt in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n",
      "Collecting fr-core-news-sm==3.7.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m16.3/16.3 MB\u001B[0m \u001B[31m12.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from fr-core-news-sm==3.7.0) (3.7.5)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.5)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.3)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.4.1)\r\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.12.3)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.4)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.32.3)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.8.2)\r\n",
      "Requirement already satisfied: jinja2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.4)\r\n",
      "Requirement already satisfied: setuptools in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (70.1.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (24.1)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.4)\r\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.2.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.12.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2024.6.2)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.5)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (13.7.1)\r\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.18.1)\r\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (7.0.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.5)\r\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.2.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.18.0)\r\n",
      "Requirement already satisfied: wrapt in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.16.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/niclasstoffregen/nlp_project/nlp_venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\r\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "!python3 -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "222dc7acd4ceed5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:32:08.026496Z",
     "start_time": "2024-07-27T19:31:59.613185Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niclasstoffregen/nlp_project/ass2/preprocessing_task_2.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data_en = data_en[mask]\n",
      "/Users/niclasstoffregen/nlp_project/ass2/preprocessing_task_2.py:26: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data_fr = data_fr[mask]\n",
      "/Users/niclasstoffregen/nlp_project/ass2/preprocessing_task_2.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_en['text'] = data_en['text'].apply(lambda x: re.sub(regex_pattern, '', x))\n",
      "/Users/niclasstoffregen/nlp_project/ass2/preprocessing_task_2.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_fr['text'] = data_fr['text'].apply(lambda x: re.sub(regex_pattern, '', x))\n"
     ]
    }
   ],
   "source": [
    "####### LOADING AND PREPROCESSING #############\n",
    "english_data, french_data = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61a7669965faa00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:32:10.099989Z",
     "start_time": "2024-07-27T19:32:08.027910Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions to tokenize data and build vocab\n",
    "spacy_fr = spacy.load('fr_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize_fr(text):\n",
    "    return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "def build_vocab(sentences, vocab_size, word_tokenize):\n",
    "    all_words = [word for sentence in sentences for word in word_tokenize(sentence)]\n",
    "    word_counts = Counter(all_words)\n",
    "    vocab = [word for word, _ in word_counts.most_common(vocab_size)]\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab, start=4)}\n",
    "    word2idx['<pad>'] = 0\n",
    "    word2idx['<unk>'] = 1\n",
    "    word2idx['<sos>'] = 2\n",
    "    word2idx['<eos>'] = 3\n",
    "    return word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f30c0ec2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:39:31.198973Z",
     "start_time": "2024-07-27T19:39:31.195058Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # Encoder\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "\n",
    "    # Decoder initialization without an SOS token\n",
    "    # The first input to the decoder could be an assumed blank token, often just zeros\n",
    "    decoder_input = torch.zeros((1, 1), dtype=torch.long)  # Assuming your vocab is zero-indexed\n",
    "    decoder_hidden = encoder_hidden  # Use the last hidden state from the encoder to start the decoder\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()  # Use model's own prediction as next input\n",
    "\n",
    "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "        # Check if decoder has generated the end of sequence, often by target length or a special condition\n",
    "        if di == target_length - 1:  # Simple condition assuming reaching the end of target tensor\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fe5e804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:32:10.105594Z",
     "start_time": "2024-07-27T19:32:10.103988Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collate function for padding\n",
    "def collate_fn(batch):\n",
    "    source_batch, target_batch = zip(*batch)\n",
    "    source_batch_padded = pad_sequence(source_batch, padding_value=vocab_en['<pad>'], batch_first=True)\n",
    "    target_batch_padded = pad_sequence(target_batch, padding_value=vocab_fr['<pad>'], batch_first=True)\n",
    "    return source_batch_padded, target_batch_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a14a700f37aee5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:32:10.107251Z",
     "start_time": "2024-07-27T19:32:10.106142Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8faf5e32ad685b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:32:10.109022Z",
     "start_time": "2024-07-27T19:32:10.107819Z"
    }
   },
   "outputs": [],
   "source": [
    "########################## TODO: USE DIFFERENT EMBEDDING MODELS #################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bf21853",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:32:10.111110Z",
     "start_time": "2024-07-27T19:32:10.109555Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_embeddings_and_create_index(path):\n",
    "    word_to_idx = {}\n",
    "    idx = 0\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            word_to_idx[word] = idx\n",
    "            idx += 1\n",
    "    return word_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "929a107a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:32:10.114856Z",
     "start_time": "2024-07-27T19:32:10.112676Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dataset preparation\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, source_sentences, target_sentences, source_vocab, target_vocab, tokenizer_source, tokenizer_target):\n",
    "        self.source_sentences = source_sentences\n",
    "        self.target_sentences = target_sentences\n",
    "        self.source_vocab = source_vocab\n",
    "        self.target_vocab = target_vocab\n",
    "        self.tokenizer_source = tokenizer_source\n",
    "        self.tokenizer_target = tokenizer_target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.source_sentences)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        source_sentence = [self.source_vocab[token] if token in self.source_vocab else self.source_vocab['<unk>'] for token in self.tokenizer_source(self.source_sentences.iloc[index])]\n",
    "        target_sentence = [self.target_vocab[token] if token in self.target_vocab else self.target_vocab['<unk>'] for token in self.tokenizer_target(self.target_sentences.iloc[index])]\n",
    "        return torch.tensor(source_sentence, dtype=torch.long), torch.tensor(target_sentence, dtype=torch.long)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cafce509",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:32:10.117597Z",
     "start_time": "2024-07-27T19:32:10.115422Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example GloVe embedding file path and embedding dimension\n",
    "\n",
    "def load_glove_embeddings(path: str, word2idx: Dict[str, int], embedding_dim: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Load GloVe embeddings from a specified file and align them with the given word index dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - path (str): The file path to the GloVe embeddings file.\n",
    "    - word2idx (Dict[str, int]): A dictionary mapping words to their corresponding indices. This dictionary defines\n",
    "      the position each word’s vector should occupy in the resulting embedding matrix.\n",
    "    - embedding_dim (int): The dimensionality of the GloVe vectors (e.g., 50, 100, 200, 300).\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: A tensor of shape (len(word2idx), embedding_dim) containing the GloVe vectors aligned according to word2idx.\n",
    "    \"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        # Initialize the embedding matrix with zeros\n",
    "        embeddings = np.zeros((len(word2idx), embedding_dim))\n",
    "        \n",
    "        # Process each line in the GloVe file\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            \n",
    "            # If the word is in the provided dictionary, update the corresponding row in embeddings\n",
    "            if word in word2idx.keys():\n",
    "                # Convert embedding values from strings to float32\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                # Place the vector in the correct index as per word2idx\n",
    "                embeddings[word2idx[word]] = vector\n",
    "    \n",
    "    # Convert the numpy array to a PyTorch tensor\n",
    "    return torch.from_numpy(embeddings)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c09042f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T20:44:48.576241Z",
     "start_time": "2024-07-27T20:44:48.569744Z"
    }
   },
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size, pretrained_embeddings):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialize the Encoder with pre-trained embeddings and a GRU layer.\n",
    "\n",
    "        Parameters:\n",
    "            hidden_size (int): The number of features in the hidden state of the GRU.\n",
    "            pretrained_embeddings (torch.Tensor): A tensor containing the pre-trained word embeddings.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        # Ensure that the pretrained embeddings are of type float32\n",
    "        if pretrained_embeddings.dtype != torch.float32:\n",
    "            pretrained_embeddings = pretrained_embeddings.to(dtype=torch.float32)\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=False)\n",
    "        embed_size = pretrained_embeddings.shape[1]  # Embedding size is the second dimension of the embeddings tensor\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, batch_first=True).float()  # Ensure GRU is initialized as float32\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Forward pass of the encoder which processes the input sequence.\n",
    "\n",
    "        Parameters:\n",
    "            input (torch.Tensor): The input sequence tensor, which should be indexed by batch.\n",
    "\n",
    "        Returns:\n",
    "            hidden (torch.Tensor): The hidden state of the GRU, representing the encoded information of the input.\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input).float()  # Ensure embedding outputs float32\n",
    "        _, hidden = self.rnn(embedded)\n",
    "        return hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, output_size, pretrained_embeddings):\n",
    "        \"\"\"\n",
    "        Initialize the Decoder with pre-trained embeddings, a GRU layer, and a linear output layer.\n",
    "\n",
    "        Parameters:\n",
    "            embed_size (int): The size of each embedding vector.\n",
    "            hidden_size (int): The number of features in the hidden state of the GRU.\n",
    "            output_size (int): The size of the output vocabulary.\n",
    "            pretrained_embeddings (torch.Tensor): A tensor containing the pre-trained word embeddings.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        # Ensure that the pretrained embeddings are of type float32\n",
    "        if pretrained_embeddings.dtype != torch.float32:\n",
    "            pretrained_embeddings = pretrained_embeddings.to(dtype=torch.float32)\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=False)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, batch_first=True).float()  # Ensure GRU is initialized as float32\n",
    "        self.fc = nn.Linear(hidden_size, output_size).float()  # Ensure Linear is initialized as float32\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Forward pass of the decoder that processes one timestep of the sequence.\n",
    "\n",
    "        Parameters:\n",
    "            x (torch.Tensor): The input tensor for the current timestep.\n",
    "            hidden (torch.Tensor): The hidden state from the last timestep.\n",
    "\n",
    "        Returns:\n",
    "            predicted (torch.Tensor): The output logits for the next word in the sequence.\n",
    "            hidden (torch.Tensor): The updated hidden state.\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(x).float()  # Ensure embedding outputs float32\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        predicted = self.fc(output)\n",
    "        return predicted, hidden\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, source, target):\n",
    "\n",
    "        \"\"\"\n",
    "        Forward pass of the Seq2Seq model which processes the entire input and target sequence.\n",
    "\n",
    "        Parameters:\n",
    "            source (torch.Tensor): The input sequence tensor.\n",
    "            target (torch.Tensor): The target sequence tensor used during training.\n",
    "\n",
    "        Returns:\n",
    "            outputs (torch.Tensor): The output from the decoder for each step in the sequence.\n",
    "        \"\"\"\n",
    "        hidden = self.encoder(source)\n",
    "        outputs, _ = self.decoder(target, hidden)\n",
    "        return outputs\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T20:51:43.188623Z",
     "start_time": "2024-07-27T20:51:43.183695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_1(model, sentence, source_vocab, target_vocab, tokenizer_source, tokenizer_target, max_length=50, device=\"cpu\"):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Tokenize the input sentence\n",
    "    tokens = tokenizer_source(sentence.lower())\n",
    "\n",
    "    # Convert tokens to indices\n",
    "    indices = [source_vocab.get(token, source_vocab['<unk>']) for token in tokens]\n",
    "    #print(f\"indices: {indices}\")\n",
    "    #print(f\"words: {[list(source_vocab.keys())[list(source_vocab.values()).index(idx)] for idx in indices]}\")\n",
    "    # Prepare the input tensor\n",
    "    input_tensor = torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    #print(f\"input tensor size: {input_tensor.size()}\")\n",
    "    # Pass through the encoder\n",
    "    with torch.no_grad():\n",
    "        encoder_hidden = model.encoder(input_tensor)\n",
    "\n",
    "    #print(f\"encoder hidden size: {encoder_hidden.size()}\")\n",
    "\n",
    "    # Initialize the decoder input and hidden state\n",
    "    decoder_input = torch.tensor([[target_vocab['<sos>']]], dtype=torch.long).to(device)\n",
    "    #print(f\"decoder input size: {decoder_input.size()}\")\n",
    "    decoder_hidden = encoder_hidden#.unsqueeze(0)  # Add batch dimension back\n",
    "    #print(f\"decoder hidden size: {decoder_hidden.size()}\")\n",
    "\n",
    "\n",
    "    # Generate the output sequence\n",
    "    output_tokens = []\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            decoder_output, decoder_hidden = model.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        next_token = topi.squeeze().item()\n",
    "\n",
    "        if next_token == target_vocab['<eos>']:\n",
    "            break\n",
    "\n",
    "        output_tokens.append(next_token)\n",
    "        decoder_input = topi.squeeze(0)#.detach()#.unsqueeze(0)\n",
    "\n",
    "    # Convert indices to tokens\n",
    "    output_sentence = [list(target_vocab.keys())[list(target_vocab.values()).index(idx)] for idx in output_tokens]\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ],
   "id": "3f1cdd4a53b9ac02",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T20:51:43.522727Z",
     "start_time": "2024-07-27T20:51:43.519280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_2(model, sentence, source_vocab, target_vocab, tokenizer_source, tokenizer_target, device=\"cpu\"):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        source = torch.tensor([source_vocab[token] if token in source_vocab else source_vocab['<unk>'] for token in tokenizer_source(sentence)], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        target = torch.tensor([target_vocab['<sos>']], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        hidden = model.encoder(source)\n",
    "        outputs = []\n",
    "        for _ in range(20):  # Limit the length of the generated sequence\n",
    "            output, hidden = model.decoder(target, hidden)\n",
    "            output = output.squeeze(0)\n",
    "            topv, target = output.topk(1)\n",
    "            #target = topi.squeeze(0)#.detach()\n",
    "            if target.item() == target_vocab['<eos>']:\n",
    "                break\n",
    "            outputs.append(target.item())\n",
    "        translated = ' '.join([list(target_vocab.keys())[list(target_vocab.values()).index(idx)] for idx in outputs])\n",
    "        return translated"
   ],
   "id": "723d8561d02784ef",
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "id": "32199614",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T20:44:49.675922Z",
     "start_time": "2024-07-27T20:44:49.673203Z"
    }
   },
   "source": [
    "\n",
    "def train(model, loader, optimizer, criterion, epochs=10, device=\"cpu\"):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for src, trg in loader:\n",
    "            # Move tensors to the correct device and ensure they are long type for indexing operations\n",
    "            src = src.to(device).long()  # Correct type for embedding layer\n",
    "            trg = trg.to(device).long()  # Correct type for embedding layer\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass: The decoder's input is all except the last word\n",
    "            output = model(src, trg[:, :-1])  \n",
    "            \n",
    "            # Since output will be in float (from linear layers, and GRU output), ensure it's float32 if not already\n",
    "            output = output.float()\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:, 1:].contiguous().view(-1)  # Target doesn't include the first <sos> token\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        average_loss = total_loss / len(loader)\n",
    "        print(predict_1(model, \"I am a student\", vocab_en, vocab_fr, tokenize_en, tokenize_fr, device=device))\n",
    "        print(predict_2(model, \"I am a book\", vocab_en, vocab_fr, tokenize_en, tokenize_fr, device=device))\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {average_loss:.4f}')"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "id": "40c6f773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T20:51:13.852872Z",
     "start_time": "2024-07-27T20:44:50.553265Z"
    }
   },
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "vocab_size = 10000\n",
    "# TODO: Do we build vocab on the entire dataset or just the training set?\n",
    "#word2idx_pre_embeddings = load_embeddings_and_create_index('glove.6B/glove.6B.100d.txt') TODO remove\n",
    "vocab_en = build_vocab(english_data[\"text\"], vocab_size, tokenize_en)\n",
    "vocab_fr = build_vocab(french_data[\"text\"], vocab_size, tokenize_fr)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(english_data, french_data, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "embedding_dim = 100\n",
    "\n",
    "# Load embeddings\n",
    "vocab_embeddings_en = load_glove_embeddings('glove.6B/glove.6B.100d.txt', vocab_en, embedding_dim)\n",
    "vocab_embeddings_fr = load_glove_embeddings('glove.6B/glove.6B.100d.txt', vocab_fr, embedding_dim)\n",
    "\n",
    "# Model instantiation\n",
    "hidden_size = 1024\n",
    "encoder = Encoder(hidden_size=hidden_size, pretrained_embeddings=vocab_embeddings_en)\n",
    "decoder = Decoder(embed_size=embedding_dim, hidden_size=hidden_size, output_size=len(vocab_fr), pretrained_embeddings=vocab_embeddings_fr)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = CrossEntropyLoss(ignore_index=vocab_fr['<pad>']).to(device)  # Move the loss function to the device\n",
    "\n",
    "dataset = TranslationDataset(english_data['text'], french_data['text'], vocab_en, vocab_fr, tokenizer_source=tokenize_en, tokenizer_target=tokenize_fr)\n",
    "loader = DataLoader(dataset, batch_size=2, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "train(model, loader, optimizer, criterion, epochs=10, device=device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 1/10, Loss: 6.1300\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 2/10, Loss: 4.6537\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 3/10, Loss: 3.5119\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 4/10, Loss: 2.5370\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 5/10, Loss: 1.7940\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 6/10, Loss: 1.2575\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 7/10, Loss: 0.8825\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 8/10, Loss: 0.5968\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 9/10, Loss: 0.4043\n",
      "indices: [16, 95, 13, 1]\n",
      "words: ['i', 'am', 'a', '<unk>']\n",
      "input tensor size: torch.Size([1, 4])\n",
      "encoder hidden size: torch.Size([1, 1, 1024])\n",
      "decoder input size: torch.Size([1, 1])\n",
      "decoder hidden size: torch.Size([1, 1, 1024])\n",
      "Epoch 10/10, Loss: 0.2856\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ef4919fc15a71ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T19:56:09.161651Z",
     "start_time": "2024-07-27T19:56:09.156364Z"
    }
   },
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b13af837",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T17:42:37.676456Z",
     "start_time": "2024-07-27T17:42:37.312828Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "GRU: Expected input to be 2D or 3D, got 1D instead",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 20\u001B[0m\n\u001B[1;32m     17\u001B[0m         translated \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([target_vocab[token] \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m outputs])\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m translated\n\u001B[0;32m---> 20\u001B[0m \u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mI am a student\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvocab_en\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvocab_fr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenize_en\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenize_fr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[17], line 10\u001B[0m, in \u001B[0;36mpredict\u001B[0;34m(model, sentence, source_vocab, target_vocab, tokenizer_source, tokenizer_target, device)\u001B[0m\n\u001B[1;32m      8\u001B[0m outputs \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m20\u001B[39m):  \u001B[38;5;66;03m# Limit the length of the generated sequence\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m     output, hidden \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     12\u001B[0m     topv, topi \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mtopk(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[11], line 67\u001B[0m, in \u001B[0;36mDecoder.forward\u001B[0;34m(self, x, hidden)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;124;03mForward pass of the decoder that processes one timestep of the sequence.\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;124;03m    hidden (torch.Tensor): The updated hidden state.\u001B[39;00m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     66\u001B[0m embedded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding(x)\u001B[38;5;241m.\u001B[39mfloat()  \u001B[38;5;66;03m# Ensure embedding outputs float32\u001B[39;00m\n\u001B[0;32m---> 67\u001B[0m output, hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43membedded\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     68\u001B[0m predicted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(output)\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m predicted, hidden\n",
      "File \u001B[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/nlp_project/nlp_venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1104\u001B[0m, in \u001B[0;36mGRU.forward\u001B[0;34m(self, input, hx)\u001B[0m\n\u001B[1;32m   1102\u001B[0m batch_sizes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m):\n\u001B[0;32m-> 1104\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGRU: Expected input to be 2D or 3D, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mD instead\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1105\u001B[0m is_batched \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m\n\u001B[1;32m   1106\u001B[0m batch_dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_first \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[0;31mValueError\u001B[0m: GRU: Expected input to be 2D or 3D, got 1D instead"
     ]
    }
   ],
   "source": ""
  },
  {
   "cell_type": "code",
   "id": "9936c567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T20:51:47.492197Z",
     "start_time": "2024-07-27T20:51:47.232176Z"
    }
   },
   "source": [
    "print(predict_1(model, \"I am a student\", vocab_en, vocab_fr, tokenize_en, tokenize_fr, device=device))\n",
    "print(predict_2(model, \"I am a book\", vocab_en, vocab_fr, tokenize_en, tokenize_fr, device=device))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", les difficultés , le conseil et la commission ont défini le contexte permettant d' une manière parfaitement coordonnée . - le 20 - madame la présidente , je crois - et j ' en reviens aux premières paroles de la situation de leur propre pays des pays comme l'\n",
      ", nous avons des inquiétudes au sujet de certaines autres amendements qui ont pris votés . il faut bien les\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4c91116faeb477c3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "nlp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
