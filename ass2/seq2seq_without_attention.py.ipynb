{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-30T18:07:22.223946Z",
     "start_time": "2024-07-30T18:07:21.201439Z"
    }
   },
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from nltk import wordpunct_tokenize\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import numpy as np\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:07:23.672886Z",
     "start_time": "2024-07-30T18:07:23.667673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device\n"
   ],
   "id": "616eece07283f143",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:07:24.045685Z",
     "start_time": "2024-07-30T18:07:24.035049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Turn text into discrete tokens.\n",
    "\n",
    "    Remove tokens that are not words.\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    tokens = wordpunct_tokenize(text)\n",
    "\n",
    "    # Only keep words\n",
    "    tokens = [token for token in tokens\n",
    "              if all(char.isalpha() for char in token)]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "class EnglishFrenchTranslations(Dataset):\n",
    "    #def __init__(self, path, max_vocab):\n",
    "    def __init__(self, df, max_vocab):\n",
    "    \n",
    "        self.max_vocab = max_vocab\n",
    "        \n",
    "        # Extra tokens to add\n",
    "        self.padding_token = '<PAD>'\n",
    "        self.start_of_sequence_token = '<SOS>'\n",
    "        self.end_of_sequence_token = '<EOS>'\n",
    "        self.unknown_word_token = '<UNK>'\n",
    "        \n",
    "        # Helper function\n",
    "        self.flatten = lambda x: [sublst for lst in x for sublst in lst]\n",
    "        \n",
    "        # Load the data into a DataFrame\n",
    "        #df = pd.read_csv(path, names=['english', 'french'], sep='|')\n",
    "        print(df.head())\n",
    "        # Tokenize inputs (English) and targets (French)\n",
    "        self.tokenize_df(df)\n",
    "\n",
    "        # To reduce computational complexity, replace rare words with <UNK>\n",
    "        self.replace_rare_tokens(df)\n",
    "        \n",
    "        # Prepare variables with mappings of tokens to indices\n",
    "        self.create_token2idx(df)\n",
    "        \n",
    "        # Remove sequences with mostly <UNK>\n",
    "        df = self.remove_mostly_unk(df)\n",
    "        \n",
    "        # Every sequence (input and target) should start with <SOS>\n",
    "        # and end with <EOS>\n",
    "        self.add_start_and_end_to_tokens(df)\n",
    "        \n",
    "        # Convert tokens to indices\n",
    "        self.tokens_to_indices(df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return example at index idx.\"\"\"\n",
    "        return self.indices_pairs[idx][0], self.indices_pairs[idx][1]\n",
    "    \n",
    "    def tokenize_df(self, df):\n",
    "        \"\"\"Turn inputs and targets into tokens.\"\"\"\n",
    "        df['tokens_inputs'] = df.english.apply(tokenize)\n",
    "        df['tokens_targets'] = df.french.apply(tokenize)\n",
    "        \n",
    "    def replace_rare_tokens(self, df):\n",
    "        \"\"\"Replace rare tokens with <UNK>.\"\"\"\n",
    "        common_tokens_inputs = self.get_most_common_tokens(\n",
    "            df.tokens_inputs.tolist(),\n",
    "        )\n",
    "        common_tokens_targets = self.get_most_common_tokens(\n",
    "            df.tokens_targets.tolist(),\n",
    "        )\n",
    "        \n",
    "        df.loc[:, 'tokens_inputs'] = df.tokens_inputs.apply(\n",
    "            lambda tokens: [token if token in common_tokens_inputs \n",
    "                            else self.unknown_word_token for token in tokens]\n",
    "        )\n",
    "        df.loc[:, 'tokens_targets'] = df.tokens_targets.apply(\n",
    "            lambda tokens: [token if token in common_tokens_targets\n",
    "                            else self.unknown_word_token for token in tokens]\n",
    "        )\n",
    "\n",
    "    def get_most_common_tokens(self, tokens_series):\n",
    "        \"\"\"Return the max_vocab most common tokens.\"\"\"\n",
    "        all_tokens = self.flatten(tokens_series)\n",
    "        # Substract 4 for <PAD>, <SOS>, <EOS>, and <UNK>\n",
    "        common_tokens = set(list(zip(*Counter(all_tokens).most_common(\n",
    "            self.max_vocab - 4)))[0])\n",
    "        return common_tokens\n",
    "\n",
    "    def remove_mostly_unk(self, df, threshold=0.99):\n",
    "        \"\"\"Remove sequences with mostly <UNK>.\"\"\"\n",
    "        def calculate_ratio(tokens):\n",
    "            # Check if tokens list is empty to avoid division by zero\n",
    "            if len(tokens) == 0:\n",
    "                return False  # Consider returning True if you want to remove empty token lists\n",
    "            return (sum(1 for token in tokens if token != '<UNK>') / len(tokens)) > threshold\n",
    "\n",
    "        # Apply the function to the DataFrame columns\n",
    "        df = df[df['tokens_inputs'].apply(calculate_ratio)]\n",
    "        df = df[df['tokens_targets'].apply(calculate_ratio)]\n",
    "        return df\n",
    "\n",
    "    def create_token2idx(self, df):\n",
    "        \"\"\"Create variables with mappings from tokens to indices.\"\"\"\n",
    "        unique_tokens_inputs = set(self.flatten(df.tokens_inputs))\n",
    "        unique_tokens_targets = set(self.flatten(df.tokens_targets))\n",
    "        \n",
    "        for token in reversed([\n",
    "            self.padding_token,\n",
    "            self.start_of_sequence_token,\n",
    "            self.end_of_sequence_token,\n",
    "            self.unknown_word_token,\n",
    "        ]):\n",
    "            if token in unique_tokens_inputs:\n",
    "                unique_tokens_inputs.remove(token)\n",
    "            if token in unique_tokens_targets:\n",
    "                unique_tokens_targets.remove(token)\n",
    "                \n",
    "        unique_tokens_inputs = sorted(list(unique_tokens_inputs))\n",
    "        unique_tokens_targets = sorted(list(unique_tokens_targets))\n",
    "\n",
    "        # Add <PAD>, <SOS>, <EOS>, and <UNK> tokens\n",
    "        for token in reversed([\n",
    "            self.padding_token,\n",
    "            self.start_of_sequence_token,\n",
    "            self.end_of_sequence_token,\n",
    "            self.unknown_word_token,\n",
    "        ]):\n",
    "            \n",
    "            unique_tokens_inputs = [token] + unique_tokens_inputs\n",
    "            unique_tokens_targets = [token] + unique_tokens_targets\n",
    "            \n",
    "        self.token2idx_inputs = {token: idx for idx, token\n",
    "                                 in enumerate(unique_tokens_inputs)}\n",
    "        self.idx2token_inputs = {idx: token for token, idx\n",
    "                                 in self.token2idx_inputs.items()}\n",
    "        \n",
    "        self.token2idx_targets = {token: idx for idx, token\n",
    "                                  in enumerate(unique_tokens_targets)}\n",
    "        self.idx2token_targets = {idx: token for token, idx\n",
    "                                  in self.token2idx_targets.items()}\n",
    "        \n",
    "    def add_start_and_end_to_tokens(self, df):\n",
    "        \"\"\"Add <SOS> and <EOS> tokens to the end of every input and output.\"\"\"\n",
    "        df['tokens_inputs'] = df['tokens_inputs'].apply(\n",
    "            lambda tokens: [self.start_of_sequence_token] + tokens + [self.end_of_sequence_token]\n",
    "        )\n",
    "        df['tokens_targets'] = df['tokens_targets'].apply(\n",
    "            lambda tokens: [self.start_of_sequence_token] + tokens + [self.end_of_sequence_token]\n",
    "        )\n",
    "        \n",
    "    def tokens_to_indices(self, df):\n",
    "        \"\"\"Convert tokens to indices.\"\"\"\n",
    "        df['indices_inputs'] = df.tokens_inputs.apply(\n",
    "            lambda tokens: [self.token2idx_inputs[token] for token in tokens])\n",
    "        df['indices_targets'] = df.tokens_targets.apply(\n",
    "            lambda tokens: [self.token2idx_targets[token] for token in tokens])\n",
    "             \n",
    "        self.indices_pairs = list(zip(df.indices_inputs, df.indices_targets))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices_pairs)\n"
   ],
   "id": "295e9621e76101c3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:07:24.554323Z",
     "start_time": "2024-07-30T18:07:24.551449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def read_file(file_path,fraction):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.readlines()  # reads all lines into a list\n",
    "        \n",
    "    # Remove newline characters at the end of each line\n",
    "    content = [line.strip() for line in content]\n",
    "    \n",
    "    # Calculate the number of lines to return based on the fraction\n",
    "    if 0 < fraction < 1:\n",
    "        end_index = int(len(content) * fraction)\n",
    "        return content[:end_index]\n",
    "    else:\n",
    "        return content[:fraction]  # Return the full list\n",
    "\n"
   ],
   "id": "a1d2c021df022dae",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:07:24.860906Z",
     "start_time": "2024-07-30T18:07:24.859038Z"
    }
   },
   "cell_type": "code",
   "source": "#### TRANSFORM OUR DATA IN THE DESIRED FORMAT#########\n",
   "id": "9cdc7f523e473c76",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:07:27.207089Z",
     "start_time": "2024-07-30T18:07:25.130181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "max_words = 5\n",
    "fraction = 20000000\n",
    "english_file_path = \"fr-en/europarl-v7.fr-en.en\"\n",
    "french_file_path = \"fr-en/europarl-v7.fr-en.fr\"\n",
    "\n",
    "# Assuming read_file function is correctly implemented and returns the data needed\n",
    "english_data = read_file(english_file_path, fraction)\n",
    "french_data = read_file(french_file_path, fraction)\n"
   ],
   "id": "3a4ac4f5434d9c2b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:07:32.374682Z",
     "start_time": "2024-07-30T18:07:27.208022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Creating new lists that only include entries with <= max_words\n",
    "max_words = 5  # Setting the max words limit, as per your example\n",
    "filtered_english_data = []\n",
    "filtered_french_data = []\n",
    "\n",
    "for en, fr in zip(english_data, french_data):\n",
    "    word_en = en.split(\" \")\n",
    "    word_fr = fr.split(\" \")\n",
    "    if len(word_en) <= max_words and len(word_fr) <= max_words:\n",
    "        filtered_english_data.append(en)\n",
    "        filtered_french_data.append(fr)\n",
    "\n",
    "print(len(filtered_english_data))\n",
    "    "
   ],
   "id": "dbd6667817b9462c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56641\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:07:34.241371Z",
     "start_time": "2024-07-30T18:07:32.375592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "df = pd.DataFrame({\n",
    "    'english': filtered_english_data,\n",
    "    'french': filtered_french_data\n",
    "})\n",
    "\n",
    "dataset = EnglishFrenchTranslations(df, max_vocab=2000)\n",
    "\n",
    "len(dataset)\n"
   ],
   "id": "41c9cd5089668871",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         english                            french\n",
      "0      Resumption of the session             Reprise de la session\n",
      "1                         Agenda                 Ordre des travaux\n",
      "2  (Applause from the PSE Group)  (Applaudissements du groupe PSE)\n",
      "3      Thank you, Mr Poettering.        Merci Monsieur Poettering.\n",
      "4           Thank you very much.                            Merci.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36955"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:07:34.245710Z",
     "start_time": "2024-07-30T18:07:34.242871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "i = 4201\n",
    "print(df[\"english\"][i])\n",
    "print(df[\"french\"][i])"
   ],
   "id": "89ed6468b79136c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environmental policy\n",
      "Politique de l'environnement\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:07:34.265697Z",
     "start_time": "2024-07-30T18:07:34.246416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def collate(batch):\n",
    "    inputs = [torch.LongTensor(item[0]) for item in batch]\n",
    "    targets = [torch.LongTensor(item[1]) for item in batch]\n",
    "    \n",
    "    # Pad sequencse so that they are all the same length (within one minibatch)\n",
    "    padded_inputs = pad_sequence(inputs, padding_value=dataset.token2idx_targets[dataset.padding_token], batch_first=True)\n",
    "    padded_targets = pad_sequence(targets, padding_value=dataset.token2idx_targets[dataset.padding_token], batch_first=True)\n",
    "    \n",
    "    # Sort by length for CUDA optimizations\n",
    "    lengths = torch.LongTensor([len(x) for x in inputs])\n",
    "    lengths, permutation = lengths.sort(dim=0, descending=True)\n",
    "\n",
    "    return padded_inputs[permutation].to(device), padded_targets[permutation].to(device), lengths.to(device)\n",
    "\n"
   ],
   "id": "ba6d751e0e8ccb48",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:07:34.280136Z",
     "start_time": "2024-07-30T18:07:34.266787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, batch_size, pretrained_embeddings):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.embedding.weight.data.copy_(pretrained_embeddings)  # Set pretrained weights\n",
    "        self.embedding.weight.requires_grad = True  # Optionally, make embeddings trainable\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.hidden_size, batch_first=True)\n",
    "    \n",
    "    # Remaining methods remain unchanged\n",
    "        \n",
    "    def forward(self, inputs, lengths):\n",
    "        self.batch_size = inputs.size(0)\n",
    "        \n",
    "        # Turn input indices into distributed embeddings\n",
    "        x = self.embedding(inputs)\n",
    "\n",
    "        # Remove padding for more efficient RNN application\n",
    "        x = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "    \n",
    "        # Apply RNN to get hidden state at all timesteps (output)\n",
    "        # and hidden state of last output (self.hidden)\n",
    "        output, self.hidden = self.gru(x, self.init_hidden())\n",
    "        \n",
    "        # Pad the sequences like they were before\n",
    "        output, _ = pad_packed_sequence(output)\n",
    "        \n",
    "        return output, self.hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Randomly initialize the weights of the RNN\n",
    "        return torch.randn(1, self.batch_size, self.hidden_size).to(device)\n"
   ],
   "id": "a2fd9dec8966f8e7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:07:34.293919Z",
     "start_time": "2024-07-30T18:07:34.281568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        vocab_size,\n",
    "        embedding_dim, \n",
    "        decoder_hidden_size,\n",
    "        encoder_hidden_size, \n",
    "        batch_size,\n",
    "        pretrained_embeddings\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder_hidden_size = encoder_hidden_size\n",
    "        self.decoder_hidden_size = decoder_hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.embedding.weight.data.copy_(pretrained_embeddings)  # Set pretrained weights\n",
    "        self.embedding.weight.requires_grad = True  # Optionally, make embeddings trainable\n",
    "        self.gru = nn.GRU(\n",
    "            self.embedding_dim + self.encoder_hidden_size, \n",
    "            self.decoder_hidden_size,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.encoder_hidden_size, self.vocab_size)\n",
    "    \n",
    "    def forward(self, input, hidden, context):\n",
    "        # input = [batch size, 1]\n",
    "        input = input.T\n",
    "        # input = [1, batch size]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # context = [n layers * n directions, batch size, hidden dim]\n",
    "        # n layers and n directions in the decoder will both always be 1, therefore:\n",
    "        # hidden = [1, batch size, hidden dim]\n",
    "        # context = [1, batch size, hidden dim]\n",
    "        # Turn target indices into distributed embeddings\n",
    "        embedded = self.embedding(input)\n",
    "        # embedded = [1, batch size, embedding dim]\n",
    "        emb_con = torch.cat((embedded, context), dim=2)\n",
    "        emb_con = emb_con.permute(1,0,2)\n",
    "        # emb_con = [1, batch size, embedding dim + hidden dim]\n",
    "        output, hidden = self.gru(emb_con, hidden)\n",
    "        \n",
    "        # Reshape the hidden states (output)\n",
    "        output = output.view(-1, output.size(2))\n",
    "        \n",
    "        # Apply a linear layer\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        # Note: without attention, we won't return attention_weights\n",
    "        return x, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Randomly initialize the weights of the RNN\n",
    "        return torch.randn(1, self.batch_size, self.decoder_hidden_size).to(device)\n"
   ],
   "id": "740c217705e38af2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:07:34.308173Z",
     "start_time": "2024-07-30T18:07:34.294824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    \"\"\"Calculate how wrong the model is.\"\"\"\n",
    "    # Use mask to only consider non-zero inputs in the loss\n",
    "    mask = real.ge(1).float().to(device)\n",
    "    \n",
    "    loss_ = criterion(pred, real) * mask \n",
    "    return torch.mean(loss_)\n",
    "\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, inputs_vocab_size, targets_vocab_size, hidden_size,\n",
    "                 embedding_dim, batch_size, targets_start_idx, targets_stop_idx,\n",
    "                 encoder_embeddings, decoder_embeddings):  # Added embeddings parameters\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.targets_start_idx = targets_start_idx\n",
    "        self.targets_stop_idx = targets_stop_idx\n",
    "        \n",
    "        # Pass pretrained embeddings to the encoder and decoder\n",
    "        self.encoder = Encoder(inputs_vocab_size, embedding_dim,\n",
    "                               hidden_size, batch_size, encoder_embeddings).to(device)\n",
    "        \n",
    "        self.decoder = Decoder(targets_vocab_size, embedding_dim,\n",
    "                               hidden_size, hidden_size, batch_size, decoder_embeddings).to(device)\n",
    "        \n",
    "        \n",
    "    def predict(self, inputs, lengths):\n",
    "        self.batch_size = inputs.size(0)\n",
    "        \n",
    "        encoder_output, context = self.encoder(\n",
    "            inputs.to(device),\n",
    "            lengths,\n",
    "        )\n",
    "        decoder_hidden = context\n",
    "\n",
    "        # Initialize the input of the decoder to be <SOS>\n",
    "        decoder_input = torch.LongTensor(\n",
    "            [[self.targets_start_idx]] * self.batch_size,\n",
    "        ).to(device)\n",
    "        \n",
    "        # Output predictions instead of loss\n",
    "        output = []\n",
    "    \n",
    "        for _ in range(20):  # max sequence length, since we work with short sentences\n",
    "            predictions, decoder_hidden = self.decoder(\n",
    "                decoder_input,\n",
    "                decoder_hidden,\n",
    "                context\n",
    "            )\n",
    "            \n",
    "            prediction = torch.multinomial(F.softmax(predictions, dim=1), 1)\n",
    "            decoder_input = prediction\n",
    "    \n",
    "            prediction = prediction.item()\n",
    "            output.append(prediction)\n",
    "    \n",
    "            if prediction == self.targets_stop_idx:\n",
    "                return output\n",
    "    \n",
    "        return output\n",
    "\n",
    "    def forward(self, inputs, targets, lengths):\n",
    "        self.batch_size = inputs.size(0)\n",
    "        \n",
    "        encoder_output, context = self.encoder(\n",
    "            inputs.to(device),\n",
    "            lengths.cpu(),  # Ensure lengths are on CPU if necessary\n",
    "        )\n",
    "        decoder_hidden = context\n",
    "        \n",
    "        # Initialize the input of the decoder to be <SOS>\n",
    "        decoder_input = torch.LongTensor(\n",
    "            [[self.targets_start_idx]] * self.batch_size,\n",
    "        ).to(device)\n",
    "        \n",
    "        # Use teacher forcing to train the model\n",
    "        loss = 0\n",
    "        for timestep in range(1, targets.size(1)):\n",
    "            predictions, decoder_hidden = self.decoder(\n",
    "                decoder_input,\n",
    "                decoder_hidden,\n",
    "                context\n",
    "            )\n",
    "            decoder_input = targets[:, timestep].unsqueeze(1).to(device)\n",
    "            \n",
    "            loss += loss_function(targets[:, timestep], predictions)\n",
    "            \n",
    "        return loss / targets.size(1)\n",
    "\n"
   ],
   "id": "847a3a015f48cba4",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:07:34.325522Z",
     "start_time": "2024-07-30T18:07:34.309015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "from typing import Dict\n",
    "# Example GloVe embedding file path and embedding dimension\n",
    "\n",
    "def load_glove_embeddings(path: str, word2idx: Dict[str, int], embedding_dim: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Load GloVe embeddings from a specified file and align them with the given word index dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - path (str): The file path to the GloVe embeddings file.\n",
    "    - word2idx (Dict[str, int]): A dictionary mapping words to their corresponding indices. This dictionary defines\n",
    "      the position each word’s vector should occupy in the resulting embedding matrix.\n",
    "    - embedding_dim (int): The dimensionality of the GloVe vectors (e.g., 50, 100, 200, 300).\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: A tensor of shape (len(word2idx), embedding_dim) containing the GloVe vectors aligned according to word2idx.\n",
    "    \"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        # Initialize the embedding matrix with zeros\n",
    "        #embeddings = np.zeros((len(word2idx), embedding_dim))\n",
    "        #better approach: init with random \n",
    "        embeddings = np.random.uniform(-0.1, 0.1, (len(word2idx), embedding_dim))\n",
    "        # Process each line in the GloVe file\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            \n",
    "            # If the word is in the provided dictionary, update the corresponding row in embeddings\n",
    "            if word in word2idx.keys():\n",
    "                # Convert embedding values from strings to float32\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                # Place the vector in the correct index as per word2idx\n",
    "                embeddings[word2idx[word]] = vector\n",
    "            else:\n",
    "                pass\n",
    "    # Convert the numpy array to a PyTorch tensor\n",
    "    return torch.from_numpy(embeddings)\n",
    "\n",
    "\n",
    "\n",
    "def load_word2vec_embeddings(path, word2idx, embedding_dim):\n",
    "    embeddings = np.random.uniform(-0.1, 0.1, (len(word2idx), embedding_dim))\n",
    "    with open(path, 'r', encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            if word in word2idx:\n",
    "                try:\n",
    "                    vector = np.asarray(values[1:], dtype='float32')\n",
    "                    embeddings[word2idx[word]] = vector\n",
    "                except ValueError:\n",
    "                    print(f\"Error converting values for word: {word}\")\n",
    "                    continue\n",
    "    return torch.from_numpy(embeddings)\n",
    "\n"
   ],
   "id": "e12de4c2a94a0477",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:07:58.026199Z",
     "start_time": "2024-07-30T18:07:34.326844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_size = int(0.90 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate, drop_last=True)\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_size = 1024\n",
    "\n",
    "# Load embeddings\n",
    "\n",
    "\n",
    "vocab_en = dataset.token2idx_inputs\n",
    "vocab_fr = dataset.token2idx_targets\n",
    "\n",
    "vocab_embeddings_en = load_word2vec_embeddings('word2vec/english.txt', vocab_en, embedding_dim)\n",
    "vocab_embeddings_fr = load_word2vec_embeddings('word2vec/france.txt', vocab_fr, embedding_dim)\n",
    "\n",
    "# Create instances of Encoder and Decoder\n",
    "encoder = Encoder(vocab_size=len(vocab_en), embedding_dim=embedding_dim, hidden_size=hidden_size, batch_size=batch_size, pretrained_embeddings=vocab_embeddings_en)\n",
    "decoder = Decoder(vocab_size=len(vocab_fr), embedding_dim=embedding_dim, decoder_hidden_size=hidden_size, encoder_hidden_size=hidden_size, batch_size=batch_size, pretrained_embeddings=vocab_embeddings_fr)\n",
    "\n",
    "\n",
    "model = EncoderDecoder(\n",
    "    inputs_vocab_size=len(dataset.token2idx_inputs),\n",
    "    targets_vocab_size=len(dataset.token2idx_targets),\n",
    "    hidden_size=256,\n",
    "    embedding_dim=embedding_dim, \n",
    "    batch_size=batch_size, \n",
    "    targets_start_idx=dataset.token2idx_targets[dataset.start_of_sequence_token],\n",
    "    targets_stop_idx=dataset.token2idx_targets[dataset.end_of_sequence_token],\n",
    "    encoder_embeddings=vocab_embeddings_en,  # Pass encoder embeddings\n",
    "    decoder_embeddings=vocab_embeddings_fr   # Pass decoder embeddings\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.001)\n",
    "\n"
   ],
   "id": "c508a735139ecea9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting values for word: communauté\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:07:58.031267Z",
     "start_time": "2024-07-30T18:07:58.027309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def calc_bleu():\n",
    "    smoothing_function = SmoothingFunction().method1\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate, drop_last=True)\n",
    "    model.eval()\n",
    "    total_loss = total = 0\n",
    "    bleu_scores = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, lengths in test_loader:\n",
    "            reference = ' '.join([\n",
    "                dataset.idx2token_inputs[idx]\n",
    "                for idx in inputs.cpu()[0].numpy()[1:-1]\n",
    "            ])\n",
    "            # print(\"english:\",reference)\n",
    "\n",
    "            target = ' '.join([\n",
    "                dataset.idx2token_targets[idx]\n",
    "                for idx in targets.cpu()[0].numpy()[1:-1]\n",
    "            ])\n",
    "            # print(\"french:\",target)\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model.predict(inputs, lengths)\n",
    "            generated = (' '.join([\n",
    "                dataset.idx2token_targets[idx]\n",
    "                for idx in outputs[:-1]\n",
    "            ]))\n",
    "            bleu_score = sentence_bleu([target], generated, smoothing_function=smoothing_function)\n",
    "            bleu_scores.append(bleu_score)\n",
    "\n",
    "    score = np.mean(bleu_scores)\n",
    "    return score\n"
   ],
   "id": "5e101c5a02e461b6",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:08:22.983146Z",
     "start_time": "2024-07-30T18:07:58.032079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "epochs=10\n",
    "\n",
    "\n",
    "# Training loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    total_loss = total = 0\n",
    "    progress_bar = tqdm(train_loader, desc='Training', leave=False)\n",
    "    for inputs, targets, lengths in progress_bar:\n",
    "        model.train()\n",
    "        inputs, targets = inputs.to(device), targets.to(device) #CHANGE ADDED\n",
    "        lengths = lengths.cpu()  #CHANGE ADDED\n",
    "\n",
    "        \n",
    "        # Clean old gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forwards pass\n",
    "        loss = model(inputs, targets, lengths)\n",
    "\n",
    "        # Perform gradient descent, backwards pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Take a step in the right direction\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record metrics\n",
    "        total_loss += loss.item()\n",
    "        total += targets.size(1)\n",
    "\n",
    "    train_loss = total_loss / total\n",
    "    \n",
    "    tqdm.write(f'epoch #{epoch + 1:3d}\\ttrain_loss: {train_loss:.2e}\\n')\n",
    "    tqdm.write(f\"bleu score: {calc_bleu()}\")\n",
    "\n",
    "    total_loss = total = 0\n"
   ],
   "id": "a47f9c564aa2a5d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #  1\ttrain_loss: 2.10e-01\n",
      "\n",
      "bleu score: 0.2024395792073884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 23\u001B[0m\n\u001B[1;32m     20\u001B[0m loss \u001B[38;5;241m=\u001B[39m model(inputs, targets, lengths)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Perform gradient descent, backwards pass\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Take a step in the right direction\u001B[39;00m\n\u001B[1;32m     26\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/Documents/tub/summer24/natural_language_processing/nlp_project/nlp_venv/lib/python3.11/site-packages/torch/_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    524\u001B[0m     )\n\u001B[0;32m--> 525\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/tub/summer24/natural_language_processing/nlp_project/nlp_venv/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 267\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/tub/summer24/natural_language_processing/nlp_project/nlp_venv/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    745\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    746\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:08:27.185278Z",
     "start_time": "2024-07-30T18:08:27.181625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def translate_text(input_text, model, dataset, device='cpu'):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Tokenize the input text using the same tokenizer used during training\n",
    "    tokens = tokenize(input_text)\n",
    "    # Convert tokens to indices using the English vocabulary\n",
    "    indices = [dataset.token2idx_inputs.get(token, dataset.token2idx_inputs['<UNK>']) for token in tokens]\n",
    "\n",
    "    # Add <SOS> and <EOS> tokens\n",
    "    indices = [dataset.token2idx_inputs[dataset.start_of_sequence_token]] + indices + [dataset.token2idx_inputs[dataset.end_of_sequence_token]]\n",
    "    \n",
    "    # Convert list of indices to tensor\n",
    "    indices_tensor = torch.LongTensor(indices).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    #print(len(indices_tensor))\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.LongTensor([len(indices)]).to(device)\n",
    "\n",
    "    # Get predictions from the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model.predict(indices_tensor, lengths)\n",
    "\n",
    "    translation = ' '.join([dataset.idx2token_targets[idx] for idx in outputs[:-1]])\n",
    "\n",
    "    return translation\n"
   ],
   "id": "7126df866173c9bf",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:08:27.529774Z",
     "start_time": "2024-07-30T18:08:27.514929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "input_text = \"the debate is closed\"\n",
    "translated_text = translate_text(input_text, model, dataset)\n",
    "print(translated_text)\n",
    "\n",
    "\n",
    "input_text = \"hello my name is erik\"\n",
    "translated_text = translate_text(input_text, model, dataset)\n",
    "print(translated_text)\n"
   ],
   "id": "5e79eea22d9dbfa4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le débat est clos\n",
      "interrompt tout ne du des <PAD> <PAD> <PAD> verbal <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "66b0406fe24bf5b1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "nlp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
