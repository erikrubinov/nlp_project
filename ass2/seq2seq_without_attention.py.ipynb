{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sequence to Sequence without Attention",
   "id": "2bb636941d662a9f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-31T16:52:55.093930Z",
     "start_time": "2024-07-31T16:52:55.090690Z"
    }
   },
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from nltk import wordpunct_tokenize\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import numpy as np\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:52:55.178687Z",
     "start_time": "2024-07-31T16:52:55.174760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device\n"
   ],
   "id": "616eece07283f143",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:52:55.201930Z",
     "start_time": "2024-07-31T16:52:55.187389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Turn text into discrete tokens.\n",
    "\n",
    "    Remove tokens that are not words.\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    tokens = wordpunct_tokenize(text)\n",
    "\n",
    "    # Only keep words\n",
    "    tokens = [token for token in tokens\n",
    "              if all(char.isalpha() for char in token)]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "class SourceTargetTranslation(Dataset):\n",
    "    #def __init__(self, path, max_vocab):\n",
    "    def __init__(self, df, max_vocab):\n",
    "    \n",
    "        self.max_vocab = max_vocab\n",
    "        \n",
    "        # Extra tokens to add\n",
    "        self.padding_token = '<PAD>'\n",
    "        self.start_of_sequence_token = '<SOS>'\n",
    "        self.end_of_sequence_token = '<EOS>'\n",
    "        self.unknown_word_token = '<UNK>'\n",
    "        \n",
    "        # Helper function\n",
    "        self.flatten = lambda x: [sublst for lst in x for sublst in lst]\n",
    "        \n",
    "        # Load the data into a DataFrame\n",
    "        print(df.head())\n",
    "        # Tokenize inputs (source) and targets (target)\n",
    "        self.tokenize_df(df)\n",
    "\n",
    "        # To reduce computational complexity, replace rare words with <UNK>\n",
    "        self.replace_rare_tokens(df)\n",
    "        \n",
    "        # Prepare variables with mappings of tokens to indices\n",
    "        self.create_token2idx(df)\n",
    "        \n",
    "        # Remove sequences with mostly <UNK>\n",
    "        df = self.remove_mostly_unk(df)\n",
    "        \n",
    "        # Every sequence (input and target) should start with <SOS>\n",
    "        # and end with <EOS>\n",
    "        self.add_start_and_end_to_tokens(df)\n",
    "        \n",
    "        # Convert tokens to indices\n",
    "        self.tokens_to_indices(df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return example at index idx.\"\"\"\n",
    "        return self.indices_pairs[idx][0], self.indices_pairs[idx][1]\n",
    "    \n",
    "    def tokenize_df(self, df):\n",
    "        \"\"\"Turn inputs and targets into tokens.\"\"\"\n",
    "        df['tokens_inputs'] = df.source.apply(tokenize)\n",
    "        df['tokens_targets'] = df.target.apply(tokenize)\n",
    "        \n",
    "    def replace_rare_tokens(self, df):\n",
    "        \"\"\"Replace rare tokens with <UNK>.\"\"\"\n",
    "        common_tokens_inputs = self.get_most_common_tokens(\n",
    "            df.tokens_inputs.tolist(),\n",
    "        )\n",
    "        common_tokens_targets = self.get_most_common_tokens(\n",
    "            df.tokens_targets.tolist(),\n",
    "        )\n",
    "        \n",
    "        df.loc[:, 'tokens_inputs'] = df.tokens_inputs.apply(\n",
    "            lambda tokens: [token if token in common_tokens_inputs \n",
    "                            else self.unknown_word_token for token in tokens]\n",
    "        )\n",
    "        df.loc[:, 'tokens_targets'] = df.tokens_targets.apply(\n",
    "            lambda tokens: [token if token in common_tokens_targets\n",
    "                            else self.unknown_word_token for token in tokens]\n",
    "        )\n",
    "\n",
    "    def get_most_common_tokens(self, tokens_series):\n",
    "        \"\"\"Return the max_vocab most common tokens.\"\"\"\n",
    "        all_tokens = self.flatten(tokens_series)\n",
    "        # Substract 4 for <PAD>, <SOS>, <EOS>, and <UNK>\n",
    "        common_tokens = set(list(zip(*Counter(all_tokens).most_common(\n",
    "            self.max_vocab - 4)))[0])\n",
    "        return common_tokens\n",
    "\n",
    "    def remove_mostly_unk(self, df, threshold=0.99):\n",
    "        \"\"\"Remove sequences with mostly <UNK>.\"\"\"\n",
    "        def calculate_ratio(tokens):\n",
    "            # Check if tokens list is empty to avoid division by zero\n",
    "            if len(tokens) == 0:\n",
    "                return False  # Consider returning True if you want to remove empty token lists\n",
    "            return (sum(1 for token in tokens if token != '<UNK>') / len(tokens)) > threshold\n",
    "\n",
    "        # Apply the function to the DataFrame columns\n",
    "        df = df[df['tokens_inputs'].apply(calculate_ratio)]\n",
    "        df = df[df['tokens_targets'].apply(calculate_ratio)]\n",
    "        return df\n",
    "\n",
    "    def create_token2idx(self, df):\n",
    "        \"\"\"Create variables with mappings from tokens to indices.\"\"\"\n",
    "        unique_tokens_inputs = set(self.flatten(df.tokens_inputs))\n",
    "        unique_tokens_targets = set(self.flatten(df.tokens_targets))\n",
    "        \n",
    "        for token in reversed([\n",
    "            self.padding_token,\n",
    "            self.start_of_sequence_token,\n",
    "            self.end_of_sequence_token,\n",
    "            self.unknown_word_token,\n",
    "        ]):\n",
    "            if token in unique_tokens_inputs:\n",
    "                unique_tokens_inputs.remove(token)\n",
    "            if token in unique_tokens_targets:\n",
    "                unique_tokens_targets.remove(token)\n",
    "                \n",
    "        unique_tokens_inputs = sorted(list(unique_tokens_inputs))\n",
    "        unique_tokens_targets = sorted(list(unique_tokens_targets))\n",
    "\n",
    "        # Add <PAD>, <SOS>, <EOS>, and <UNK> tokens\n",
    "        for token in reversed([\n",
    "            self.padding_token,\n",
    "            self.start_of_sequence_token,\n",
    "            self.end_of_sequence_token,\n",
    "            self.unknown_word_token,\n",
    "        ]):\n",
    "            \n",
    "            unique_tokens_inputs = [token] + unique_tokens_inputs\n",
    "            unique_tokens_targets = [token] + unique_tokens_targets\n",
    "            \n",
    "        self.token2idx_inputs = {token: idx for idx, token\n",
    "                                 in enumerate(unique_tokens_inputs)}\n",
    "        self.idx2token_inputs = {idx: token for token, idx\n",
    "                                 in self.token2idx_inputs.items()}\n",
    "        \n",
    "        self.token2idx_targets = {token: idx for idx, token\n",
    "                                  in enumerate(unique_tokens_targets)}\n",
    "        self.idx2token_targets = {idx: token for token, idx\n",
    "                                  in self.token2idx_targets.items()}\n",
    "        \n",
    "    def add_start_and_end_to_tokens(self, df):\n",
    "        \"\"\"Add <SOS> and <EOS> tokens to the end of every input and output.\"\"\"\n",
    "        df['tokens_inputs'] = df['tokens_inputs'].apply(\n",
    "            lambda tokens: [self.start_of_sequence_token] + tokens + [self.end_of_sequence_token]\n",
    "        )\n",
    "        df['tokens_targets'] = df['tokens_targets'].apply(\n",
    "            lambda tokens: [self.start_of_sequence_token] + tokens + [self.end_of_sequence_token]\n",
    "        )\n",
    "        \n",
    "    def tokens_to_indices(self, df):\n",
    "        \"\"\"Convert tokens to indices.\"\"\"\n",
    "        df['indices_inputs'] = df.tokens_inputs.apply(\n",
    "            lambda tokens: [self.token2idx_inputs[token] for token in tokens])\n",
    "        df['indices_targets'] = df.tokens_targets.apply(\n",
    "            lambda tokens: [self.token2idx_targets[token] for token in tokens])\n",
    "             \n",
    "        self.indices_pairs = list(zip(df.indices_inputs, df.indices_targets))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices_pairs)\n"
   ],
   "id": "295e9621e76101c3",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:52:55.223271Z",
     "start_time": "2024-07-31T16:52:55.219424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def read_file(file_path,fraction):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.readlines()  # reads all lines into a list\n",
    "        \n",
    "    # Remove newline characters at the end of each line\n",
    "    content = [line.strip() for line in content]\n",
    "    \n",
    "    # Calculate the number of lines to return based on the fraction\n",
    "    if 0 < fraction < 1:\n",
    "        end_index = int(len(content) * fraction)\n",
    "        return content[:end_index]\n",
    "    else:\n",
    "        return content[:fraction]  # Return the full list\n",
    "\n"
   ],
   "id": "a1d2c021df022dae",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:52:55.250373Z",
     "start_time": "2024-07-31T16:52:55.248619Z"
    }
   },
   "cell_type": "code",
   "source": "#### TRANSFORM OUR DATA IN THE DESIRED FORMAT#########\n",
   "id": "9cdc7f523e473c76",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load data",
   "id": "db8daed1dbbcfd8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:52:55.265369Z",
     "start_time": "2024-07-31T16:52:55.262713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(fraction=20000000):\n",
    "    source_file_path = \"fr-en/europarl-v7.fr-en.en\"\n",
    "    target_file_path = \"fr-en/europarl-v7.fr-en.fr\"\n",
    "    \n",
    "    # Assuming read_file function is correctly implemented and returns the data needed\n",
    "    source_data = read_file(source_file_path, fraction)\n",
    "    target_data = read_file(target_file_path, fraction)\n",
    "    \n",
    "    return source_data, target_data\n"
   ],
   "id": "3a4ac4f5434d9c2b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:53:25.288939Z",
     "start_time": "2024-07-31T16:53:25.285069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare(source_data, target_data, max_vocab, max_words):\n",
    "    # Creating new lists that only include entries with <= max_words\n",
    "    filtered_source_data = []\n",
    "    filtered_target_data = []\n",
    "    \n",
    "    for source, target in zip(source_data, target_data):\n",
    "        word_source = source.split(\" \")\n",
    "        word_target = target.split(\" \")\n",
    "        if len(word_source) <= max_words and len(word_target) <= max_words:\n",
    "            filtered_source_data.append(source)\n",
    "            filtered_target_data.append(target)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'source': filtered_source_data,\n",
    "        'target': filtered_target_data\n",
    "    })\n",
    "    \n",
    "    dataset = SourceTargetTranslation(df, max_vocab=max_vocab)\n",
    "    return dataset, df\n",
    "            "
   ],
   "id": "dbd6667817b9462c",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:52:55.430675Z",
     "start_time": "2024-07-31T16:52:55.295393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def collate(batch):\n",
    "    inputs = [torch.LongTensor(item[0]) for item in batch]\n",
    "    targets = [torch.LongTensor(item[1]) for item in batch]\n",
    "    \n",
    "    # Pad sequencse so that they are all the same length (within one minibatch)\n",
    "    padded_inputs = pad_sequence(inputs, padding_value=dataset.token2idx_targets[dataset.padding_token], batch_first=True)\n",
    "    padded_targets = pad_sequence(targets, padding_value=dataset.token2idx_targets[dataset.padding_token], batch_first=True)\n",
    "    \n",
    "    # Sort by length for CUDA optimizations\n",
    "    lengths = torch.LongTensor([len(x) for x in inputs])\n",
    "    lengths, permutation = lengths.sort(dim=0, descending=True)\n",
    "\n",
    "    return padded_inputs[permutation].to(device), padded_targets[permutation].to(device), lengths.to(device)\n",
    "\n"
   ],
   "id": "ba6d751e0e8ccb48",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:52:55.441164Z",
     "start_time": "2024-07-31T16:52:55.431652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, batch_size, pretrained_embeddings):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.embedding.weight.data.copy_(pretrained_embeddings)  # Set pretrained weights\n",
    "        self.embedding.weight.requires_grad = True  # Optionally, make embeddings trainable\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.hidden_size, batch_first=True)\n",
    "    \n",
    "    # Remaining methods remain unchanged\n",
    "        \n",
    "    def forward(self, inputs, lengths):\n",
    "        self.batch_size = inputs.size(0)\n",
    "        \n",
    "        # Turn input indices into distributed embeddings\n",
    "        x = self.embedding(inputs)\n",
    "\n",
    "        # Remove padding for more efficient RNN application\n",
    "        x = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "    \n",
    "        # Apply RNN to get hidden state at all timesteps (output)\n",
    "        # and hidden state of last output (self.hidden)\n",
    "        output, self.hidden = self.gru(x, self.init_hidden())\n",
    "        \n",
    "        # Pad the sequences like they were before\n",
    "        output, _ = pad_packed_sequence(output)\n",
    "        \n",
    "        return output, self.hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Randomly initialize the weights of the RNN\n",
    "        return torch.randn(1, self.batch_size, self.hidden_size).to(device)\n"
   ],
   "id": "a2fd9dec8966f8e7",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:52:55.454098Z",
     "start_time": "2024-07-31T16:52:55.441964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        vocab_size,\n",
    "        embedding_dim, \n",
    "        decoder_hidden_size,\n",
    "        encoder_hidden_size, \n",
    "        batch_size,\n",
    "        pretrained_embeddings\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder_hidden_size = encoder_hidden_size\n",
    "        self.decoder_hidden_size = decoder_hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.embedding.weight.data.copy_(pretrained_embeddings)  # Set pretrained weights\n",
    "        self.embedding.weight.requires_grad = True  # Optionally, make embeddings trainable\n",
    "        self.gru = nn.GRU(\n",
    "            self.embedding_dim + self.encoder_hidden_size, \n",
    "            self.decoder_hidden_size,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.encoder_hidden_size, self.vocab_size)\n",
    "    \n",
    "    def forward(self, input, hidden, context):\n",
    "        # input = [batch size, 1]\n",
    "        input = input.T\n",
    "        # input = [1, batch size]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # context = [n layers * n directions, batch size, hidden dim]\n",
    "        # n layers and n directions in the decoder will both always be 1, therefore:\n",
    "        # hidden = [1, batch size, hidden dim]\n",
    "        # context = [1, batch size, hidden dim]\n",
    "        # Turn target indices into distributed embeddings\n",
    "        embedded = self.embedding(input)\n",
    "        # embedded = [1, batch size, embedding dim]\n",
    "        emb_con = torch.cat((embedded, context), dim=2)\n",
    "        emb_con = emb_con.permute(1,0,2)\n",
    "        # emb_con = [1, batch size, embedding dim + hidden dim]\n",
    "        output, hidden = self.gru(emb_con, hidden)\n",
    "        \n",
    "        # Reshape the hidden states (output)\n",
    "        output = output.view(-1, output.size(2))\n",
    "        \n",
    "        # Apply a linear layer\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        # Note: without attention, we won't return attention_weights\n",
    "        return x, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Randomly initialize the weights of the RNN\n",
    "        return torch.randn(1, self.batch_size, self.decoder_hidden_size).to(device)\n"
   ],
   "id": "740c217705e38af2",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:52:55.467369Z",
     "start_time": "2024-07-31T16:52:55.455332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    \"\"\"Calculate how wrong the model is.\"\"\"\n",
    "    # Use mask to only consider non-zero inputs in the loss\n",
    "    mask = real.ge(1).float().to(device)\n",
    "    \n",
    "    loss_ = criterion(pred, real) * mask \n",
    "    return torch.mean(loss_)\n",
    "\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, inputs_vocab_size, targets_vocab_size, hidden_size,\n",
    "                 embedding_dim, batch_size, targets_start_idx, targets_stop_idx,\n",
    "                 encoder_embeddings, decoder_embeddings):  # Added embeddings parameters\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.targets_start_idx = targets_start_idx\n",
    "        self.targets_stop_idx = targets_stop_idx\n",
    "        \n",
    "        # Pass pretrained embeddings to the encoder and decoder\n",
    "        self.encoder = Encoder(inputs_vocab_size, embedding_dim,\n",
    "                               hidden_size, batch_size, encoder_embeddings).to(device)\n",
    "        \n",
    "        self.decoder = Decoder(targets_vocab_size, embedding_dim,\n",
    "                               hidden_size, hidden_size, batch_size, decoder_embeddings).to(device)\n",
    "        \n",
    "        \n",
    "    def predict(self, inputs, lengths):\n",
    "        self.batch_size = inputs.size(0)\n",
    "        \n",
    "        encoder_output, context = self.encoder(\n",
    "            inputs.to(device),\n",
    "            lengths,\n",
    "        )\n",
    "        decoder_hidden = context\n",
    "\n",
    "        # Initialize the input of the decoder to be <SOS>\n",
    "        decoder_input = torch.LongTensor(\n",
    "            [[self.targets_start_idx]] * self.batch_size,\n",
    "        ).to(device)\n",
    "        \n",
    "        # Output predictions instead of loss\n",
    "        output = []\n",
    "    \n",
    "        for _ in range(20):  # max sequence length, since we work with short sentences\n",
    "            predictions, decoder_hidden = self.decoder(\n",
    "                decoder_input,\n",
    "                decoder_hidden,\n",
    "                context\n",
    "            )\n",
    "            \n",
    "            prediction = torch.multinomial(F.softmax(predictions, dim=1), 1)\n",
    "            decoder_input = prediction\n",
    "    \n",
    "            prediction = prediction.item()\n",
    "            output.append(prediction)\n",
    "    \n",
    "            if prediction == self.targets_stop_idx:\n",
    "                return output\n",
    "    \n",
    "        return output\n",
    "\n",
    "    def forward(self, inputs, targets, lengths):\n",
    "        self.batch_size = inputs.size(0)\n",
    "        \n",
    "        encoder_output, context = self.encoder(\n",
    "            inputs.to(device),\n",
    "            lengths.cpu(),  # Ensure lengths are on CPU if necessary\n",
    "        )\n",
    "        decoder_hidden = context\n",
    "        \n",
    "        # Initialize the input of the decoder to be <SOS>\n",
    "        decoder_input = torch.LongTensor(\n",
    "            [[self.targets_start_idx]] * self.batch_size,\n",
    "        ).to(device)\n",
    "        \n",
    "        # Use teacher forcing to train the model\n",
    "        loss = 0\n",
    "        for timestep in range(1, targets.size(1)):\n",
    "            predictions, decoder_hidden = self.decoder(\n",
    "                decoder_input,\n",
    "                decoder_hidden,\n",
    "                context\n",
    "            )\n",
    "            decoder_input = targets[:, timestep].unsqueeze(1).to(device)\n",
    "            \n",
    "            loss += loss_function(targets[:, timestep], predictions)\n",
    "            \n",
    "        return loss / targets.size(1)\n",
    "\n"
   ],
   "id": "847a3a015f48cba4",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:52:55.480690Z",
     "start_time": "2024-07-31T16:52:55.468222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "from typing import Dict\n",
    "# Example GloVe embedding file path and embedding dimension\n",
    "\n",
    "def load_glove_embeddings(path: str, word2idx: Dict[str, int], embedding_dim: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Load GloVe embeddings from a specified file and align them with the given word index dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - path (str): The file path to the GloVe embeddings file.\n",
    "    - word2idx (Dict[str, int]): A dictionary mapping words to their corresponding indices. This dictionary defines\n",
    "      the position each word’s vector should occupy in the resulting embedding matrix.\n",
    "    - embedding_dim (int): The dimensionality of the GloVe vectors (e.g., 50, 100, 200, 300).\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: A tensor of shape (len(word2idx), embedding_dim) containing the GloVe vectors aligned according to word2idx.\n",
    "    \"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        # Initialize the embedding matrix with zeros\n",
    "        #embeddings = np.zeros((len(word2idx), embedding_dim))\n",
    "        #better approach: init with random \n",
    "        embeddings = np.random.uniform(-0.1, 0.1, (len(word2idx), embedding_dim))\n",
    "        # Process each line in the GloVe file\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            \n",
    "            # If the word is in the provided dictionary, update the corresponding row in embeddings\n",
    "            if word in word2idx.keys():\n",
    "                # Convert embedding values from strings to float32\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                # Place the vector in the correct index as per word2idx\n",
    "                embeddings[word2idx[word]] = vector\n",
    "            else:\n",
    "                pass\n",
    "    # Convert the numpy array to a PyTorch tensor\n",
    "    return torch.from_numpy(embeddings)\n",
    "\n",
    "\n",
    "\n",
    "def load_word2vec_embeddings(path, word2idx, embedding_dim):\n",
    "    embeddings = np.random.uniform(-0.1, 0.1, (len(word2idx), embedding_dim))\n",
    "    with open(path, 'r', encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            if word in word2idx:\n",
    "                try:\n",
    "                    vector = np.asarray(values[1:], dtype='float32')\n",
    "                    embeddings[word2idx[word]] = vector\n",
    "                except ValueError:\n",
    "                    print(f\"Error converting values for word: {word}\")\n",
    "                    continue\n",
    "    return torch.from_numpy(embeddings)\n",
    "\n"
   ],
   "id": "e12de4c2a94a0477",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:52:55.494067Z",
     "start_time": "2024-07-31T16:52:55.481473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "def load_and_init(dataset, embedding_dim, hidden_dim, batch_size):\n",
    "\n",
    "    train_size = int(0.90 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate, drop_last=True)\n",
    "        \n",
    "    # Load embeddings\n",
    "    \n",
    "    source_embeddings_path = 'glove.6B/glove.6B.300d.txt'\n",
    "    target_embeddings_path = 'fasttext/cc.fr.300.vec'\n",
    "    \n",
    "    vocab_source = dataset.token2idx_inputs\n",
    "    vocab_target = dataset.token2idx_targets\n",
    "    \n",
    "    vocab_embeddings_source = load_word2vec_embeddings(source_embeddings_path, vocab_source, embedding_dim)\n",
    "    vocab_embeddings_target = load_word2vec_embeddings(target_embeddings_path, vocab_target, embedding_dim)\n",
    "    \n",
    "    \n",
    "    model = EncoderDecoder(\n",
    "        inputs_vocab_size=len(dataset.token2idx_inputs),\n",
    "        targets_vocab_size=len(dataset.token2idx_targets),\n",
    "        hidden_size=hidden_dim,\n",
    "        embedding_dim=embedding_dim, \n",
    "        batch_size=batch_size, \n",
    "        targets_start_idx=dataset.token2idx_targets[dataset.start_of_sequence_token],\n",
    "        targets_stop_idx=dataset.token2idx_targets[dataset.end_of_sequence_token],\n",
    "        encoder_embeddings=vocab_embeddings_source,  # Pass encoder embeddings\n",
    "        decoder_embeddings=vocab_embeddings_target   # Pass decoder embeddings\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.001)\n",
    "\n",
    "    return model, optimizer, train_loader, test_dataset, vocab_embeddings_source, vocab_embeddings_target\n"
   ],
   "id": "c508a735139ecea9",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:52:55.507038Z",
     "start_time": "2024-07-31T16:52:55.494968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def calc_bleu(model, translation_dataset: SourceTargetTranslation, test_dataset, collate_fn):\n",
    "    smoothing_function = SmoothingFunction().method1\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate, drop_last=True)\n",
    "    model.eval()\n",
    "    total_loss = total = 0\n",
    "    bleu_scores = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, lengths in test_loader:\n",
    "            reference = ' '.join([\n",
    "                translation_dataset.idx2token_inputs[idx]\n",
    "                for idx in inputs.cpu()[0].numpy()[1:-1]\n",
    "            ])\n",
    "            # print(\"source:\",reference)\n",
    "\n",
    "            target = ' '.join([\n",
    "                translation_dataset.idx2token_targets[idx]\n",
    "                for idx in targets.cpu()[0].numpy()[1:-1]\n",
    "            ])\n",
    "            # print(\"target:\",target)\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model.predict(inputs, lengths)\n",
    "            generated = (' '.join([\n",
    "                translation_dataset.idx2token_targets[idx]\n",
    "                for idx in outputs[:-1]\n",
    "            ]))\n",
    "            bleu_score = sentence_bleu([target], generated, smoothing_function=smoothing_function)\n",
    "            bleu_scores.append(bleu_score)\n",
    "\n",
    "    score = np.mean(bleu_scores)\n",
    "    return score\n"
   ],
   "id": "5e101c5a02e461b6",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:52:55.520282Z",
     "start_time": "2024-07-31T16:52:55.507869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, optimizer, translation_dataset: SourceTargetTranslation, train_loader, test_dataset, collate_fn, file_suffix, epochs=10):\n",
    "    results_list = []\n",
    "    results = pd.DataFrame(columns=[\"epoch\", \"train_loss\", \"train_ppl\", \"bleu\"])\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        total_loss = total = 0\n",
    "        progress_bar = tqdm(train_loader, desc='Training', leave=False)\n",
    "        for inputs, targets, lengths in progress_bar:\n",
    "            model.train()\n",
    "            inputs, targets = inputs.to(device), targets.to(device) #CHANGE ADDED\n",
    "            lengths = lengths.cpu()  #CHANGE ADDED\n",
    "    \n",
    "            \n",
    "            # Clean old gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # Forwards pass\n",
    "            loss = model(inputs, targets, lengths)\n",
    "    \n",
    "            # Perform gradient descent, backwards pass\n",
    "            loss.backward()\n",
    "    \n",
    "            # Take a step in the right direction\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Record metrics\n",
    "            total_loss += loss.item()\n",
    "            total += targets.size(1)\n",
    "    \n",
    "        train_loss = total_loss / total\n",
    "        \n",
    "        bleu = calc_bleu(model, translation_dataset, test_dataset, collate_fn)\n",
    "        tqdm.write(f'epoch #{epoch + 1:3d}\\ttrain_loss: {train_loss:.2e}\\tBLEU: {bleu:.4f}\\n')\n",
    "        \n",
    "        results_list.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_ppl\": np.exp(train_loss),\n",
    "            \"bleu\": bleu\n",
    "        })\n",
    "    \n",
    "        total_loss = total = 0\n",
    "    results = pd.DataFrame(results_list)\n",
    "    results.to_csv(f\"reports/csv/task_5_pivot_{file_suffix}.csv\", index=False)\n"
   ],
   "id": "a47f9c564aa2a5d",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:52:55.533018Z",
     "start_time": "2024-07-31T16:52:55.521012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def translate_text(input_text, model, dataset, device='cpu'):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Tokenize the input text using the same tokenizer used during training\n",
    "    tokens = tokenize(input_text)\n",
    "    # Convert tokens to indices using the _source  vocabulary\n",
    "    indices = [dataset.token2idx_inputs.get(token, dataset.token2idx_inputs['<UNK>']) for token in tokens]\n",
    "\n",
    "    # Add <SOS> and <EOS> tokens\n",
    "    indices = [dataset.token2idx_inputs[dataset.start_of_sequence_token]] + indices + [dataset.token2idx_inputs[dataset.end_of_sequence_token]]\n",
    "    \n",
    "    # Convert list of indices to tensor\n",
    "    indices_tensor = torch.LongTensor(indices).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    #print(len(indices_tensor))\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.LongTensor([len(indices)]).to(device)\n",
    "\n",
    "    # Get predictions from the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model.predict(indices_tensor, lengths)\n",
    "\n",
    "    translation = ' '.join([dataset.idx2token_targets[idx] for idx in outputs[:-1]])\n",
    "\n",
    "    return translation\n"
   ],
   "id": "7126df866173c9bf",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "85c000db54395e4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:53:03.278679Z",
     "start_time": "2024-07-31T16:53:03.276752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## EXP 1: 2000 vocabulary and max. 5 words, glove + fasttext embeddings\n",
    "max_words = 5\n",
    "fraction = 20000000\n",
    "max_vocab = 2000"
   ],
   "id": "4f557ca39b05b0d1",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T16:53:38.529374Z",
     "start_time": "2024-07-31T16:53:30.275324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "source_data, target_data = load_data(fraction)\n",
    "dataset, df = prepare(source_data, target_data, max_vocab, max_words)\n",
    "model, optimizer, train_loader, test_dataset, _, _ = load_and_init(dataset, 300, 256, 64)\n",
    "train(model, optimizer, dataset, train_loader, test_dataset, collate, \"exp1\", 10)"
   ],
   "id": "50fde32a5fd82e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          source                            target\n",
      "0      Resumption of the session             Reprise de la session\n",
      "1                         Agenda                 Ordre des travaux\n",
      "2  (Applause from the PSE Group)  (Applaudissements du groupe PSE)\n",
      "3      Thank you, Mr Poettering.        Merci Monsieur Poettering.\n",
      "4           Thank you very much.                            Merci.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'glove.6B/glove.6B.300d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m source_data, target_data \u001B[38;5;241m=\u001B[39m load_data(fraction)\n\u001B[1;32m      2\u001B[0m dataset, df \u001B[38;5;241m=\u001B[39m prepare(source_data, target_data, max_vocab, max_words)\n\u001B[0;32m----> 3\u001B[0m model, optimizer, train_loader, test_dataset, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mload_and_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m train(model, optimizer, dataset, train_loader, test_dataset, collate, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexp1\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m10\u001B[39m)\n",
      "Cell \u001B[0;32mIn[24], line 19\u001B[0m, in \u001B[0;36mload_and_init\u001B[0;34m(dataset, embedding_dim, hidden_dim, batch_size)\u001B[0m\n\u001B[1;32m     16\u001B[0m vocab_source \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mtoken2idx_inputs\n\u001B[1;32m     17\u001B[0m vocab_target \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mtoken2idx_targets\n\u001B[0;32m---> 19\u001B[0m vocab_embeddings_source \u001B[38;5;241m=\u001B[39m \u001B[43mload_word2vec_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource_embeddings_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvocab_source\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_dim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m vocab_embeddings_target \u001B[38;5;241m=\u001B[39m load_word2vec_embeddings(target_embeddings_path, vocab_target, embedding_dim)\n\u001B[1;32m     23\u001B[0m model \u001B[38;5;241m=\u001B[39m EncoderDecoder(\n\u001B[1;32m     24\u001B[0m     inputs_vocab_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(dataset\u001B[38;5;241m.\u001B[39mtoken2idx_inputs),\n\u001B[1;32m     25\u001B[0m     targets_vocab_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(dataset\u001B[38;5;241m.\u001B[39mtoken2idx_targets),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     32\u001B[0m     decoder_embeddings\u001B[38;5;241m=\u001B[39mvocab_embeddings_target   \u001B[38;5;66;03m# Pass decoder embeddings\u001B[39;00m\n\u001B[1;32m     33\u001B[0m )\u001B[38;5;241m.\u001B[39mto(device)\n",
      "Cell \u001B[0;32mIn[23], line 42\u001B[0m, in \u001B[0;36mload_word2vec_embeddings\u001B[0;34m(path, word2idx, embedding_dim)\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_word2vec_embeddings\u001B[39m(path, word2idx, embedding_dim):\n\u001B[1;32m     41\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39muniform(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.1\u001B[39m, (\u001B[38;5;28mlen\u001B[39m(word2idx), embedding_dim))\n\u001B[0;32m---> 42\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlatin1\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m f:\n\u001B[1;32m     44\u001B[0m             values \u001B[38;5;241m=\u001B[39m line\u001B[38;5;241m.\u001B[39mstrip()\u001B[38;5;241m.\u001B[39msplit()\n",
      "File \u001B[0;32m~/Documents/tub/summer24/natural_language_processing/nlp_project/nlp_venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    322\u001B[0m     )\n\u001B[0;32m--> 324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'glove.6B/glove.6B.300d.txt'"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T18:08:27.529774Z",
     "start_time": "2024-07-30T18:08:27.514929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "input_text = \"the debate is closed\"\n",
    "translated_text = translate_text(input_text, model, dataset)\n",
    "print(translated_text)\n",
    "\n",
    "\n",
    "input_text = \"hello my name is erik\"\n",
    "translated_text = translate_text(input_text, model, dataset)\n",
    "print(translated_text)\n"
   ],
   "id": "5e79eea22d9dbfa4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le débat est clos\n",
      "interrompt tout ne du des <PAD> <PAD> <PAD> verbal <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "66b0406fe24bf5b1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "nlp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
